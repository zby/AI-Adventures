<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">@import url(https://themes.googleusercontent.com/fonts/css?kit=DFQxm4rd7fRHgM9OTejWVT5Vho6BE7M80rHXEVKqXWegg2XYR88pwOsaJkfiF7cJu5e0vFtnyLdhsxviZUUN-U0KZVwUvSK-LyXz4qcE1hc);ul.lst-kix_list_1-0{list-style-type:none}.lst-kix_list_3-0>li:before{content:"\0025cf   "}ul.lst-kix_list_5-7{list-style-type:none}ul.lst-kix_list_5-8{list-style-type:none}.lst-kix_list_3-1>li:before{content:"\0025cb   "}.lst-kix_list_3-2>li:before{content:"\0025a0   "}ul.lst-kix_list_5-5{list-style-type:none}ul.lst-kix_list_5-6{list-style-type:none}.lst-kix_list_6-0>li{counter-increment:lst-ctn-kix_list_6-0}ul.lst-kix_list_1-3{list-style-type:none}.lst-kix_list_3-5>li:before{content:"\0025a0   "}ul.lst-kix_list_5-0{list-style-type:none}ul.lst-kix_list_1-4{list-style-type:none}ul.lst-kix_list_1-1{list-style-type:none}.lst-kix_list_3-4>li:before{content:"\0025a0   "}ul.lst-kix_list_1-2{list-style-type:none}ul.lst-kix_list_5-3{list-style-type:none}ul.lst-kix_list_1-7{list-style-type:none}.lst-kix_list_3-3>li:before{content:"\0025a0   "}ul.lst-kix_list_5-4{list-style-type:none}ul.lst-kix_list_1-8{list-style-type:none}ul.lst-kix_list_5-1{list-style-type:none}ul.lst-kix_list_1-5{list-style-type:none}ul.lst-kix_list_5-2{list-style-type:none}ul.lst-kix_list_1-6{list-style-type:none}.lst-kix_list_3-8>li:before{content:"\0025a0   "}.lst-kix_list_3-6>li:before{content:"\0025a0   "}.lst-kix_list_3-7>li:before{content:"\0025a0   "}.lst-kix_list_5-0>li:before{content:"\0025cf   "}ol.lst-kix_list_6-0{list-style-type:none}.lst-kix_list_4-8>li:before{content:"\0025a0   "}.lst-kix_list_5-3>li:before{content:"\0025a0   "}.lst-kix_list_4-7>li:before{content:"\0025a0   "}.lst-kix_list_5-2>li:before{content:"\0025a0   "}.lst-kix_list_5-1>li:before{content:"\0025cb   "}ul.lst-kix_list_4-8{list-style-type:none}.lst-kix_list_5-7>li:before{content:"\0025a0   "}ul.lst-kix_list_4-6{list-style-type:none}.lst-kix_list_5-6>li:before{content:"\0025a0   "}.lst-kix_list_5-8>li:before{content:"\0025a0   "}ul.lst-kix_list_4-7{list-style-type:none}ul.lst-kix_list_4-0{list-style-type:none}ul.lst-kix_list_4-1{list-style-type:none}.lst-kix_list_5-4>li:before{content:"\0025a0   "}ul.lst-kix_list_4-4{list-style-type:none}.lst-kix_list_5-5>li:before{content:"\0025a0   "}ul.lst-kix_list_4-5{list-style-type:none}ul.lst-kix_list_4-2{list-style-type:none}ul.lst-kix_list_4-3{list-style-type:none}.lst-kix_list_6-1>li:before{content:"\0025cb   "}.lst-kix_list_6-3>li:before{content:"\0025a0   "}.lst-kix_list_6-0>li:before{content:"" counter(lst-ctn-kix_list_6-0,decimal) ". "}.lst-kix_list_6-4>li:before{content:"\0025a0   "}.lst-kix_list_6-2>li:before{content:"\0025a0   "}.lst-kix_list_6-8>li:before{content:"\0025a0   "}.lst-kix_list_6-5>li:before{content:"\0025a0   "}.lst-kix_list_6-7>li:before{content:"\0025a0   "}.lst-kix_list_6-6>li:before{content:"\0025a0   "}.lst-kix_list_2-6>li:before{content:"\0025a0   "}.lst-kix_list_2-7>li:before{content:"\0025a0   "}.lst-kix_list_2-4>li:before{content:"\0025a0   "}.lst-kix_list_2-5>li:before{content:"\0025a0   "}.lst-kix_list_2-8>li:before{content:"\0025a0   "}ul.lst-kix_list_3-7{list-style-type:none}ul.lst-kix_list_3-8{list-style-type:none}ul.lst-kix_list_3-1{list-style-type:none}ul.lst-kix_list_3-2{list-style-type:none}ul.lst-kix_list_3-0{list-style-type:none}ul.lst-kix_list_3-5{list-style-type:none}ul.lst-kix_list_3-6{list-style-type:none}ul.lst-kix_list_3-3{list-style-type:none}ul.lst-kix_list_3-4{list-style-type:none}.lst-kix_list_4-0>li:before{content:"\0025cf   "}.lst-kix_list_4-1>li:before{content:"\0025cb   "}.lst-kix_list_4-4>li:before{content:"\0025a0   "}.lst-kix_list_4-3>li:before{content:"\0025a0   "}.lst-kix_list_4-5>li:before{content:"\0025a0   "}.lst-kix_list_4-2>li:before{content:"\0025a0   "}.lst-kix_list_4-6>li:before{content:"\0025a0   "}ul.lst-kix_list_6-6{list-style-type:none}ul.lst-kix_list_6-7{list-style-type:none}ul.lst-kix_list_6-4{list-style-type:none}ul.lst-kix_list_2-8{list-style-type:none}ul.lst-kix_list_6-5{list-style-type:none}ul.lst-kix_list_6-8{list-style-type:none}ul.lst-kix_list_2-2{list-style-type:none}.lst-kix_list_1-0>li:before{content:"\0025cf   "}ul.lst-kix_list_2-3{list-style-type:none}ul.lst-kix_list_2-0{list-style-type:none}ul.lst-kix_list_2-1{list-style-type:none}ul.lst-kix_list_6-2{list-style-type:none}ul.lst-kix_list_2-6{list-style-type:none}ul.lst-kix_list_6-3{list-style-type:none}.lst-kix_list_1-1>li:before{content:"\0025cb   "}.lst-kix_list_1-2>li:before{content:"\0025a0   "}ul.lst-kix_list_2-7{list-style-type:none}ul.lst-kix_list_2-4{list-style-type:none}ul.lst-kix_list_6-1{list-style-type:none}ul.lst-kix_list_2-5{list-style-type:none}.lst-kix_list_1-3>li:before{content:"\0025a0   "}.lst-kix_list_1-4>li:before{content:"\0025a0   "}.lst-kix_list_1-7>li:before{content:"\0025a0   "}.lst-kix_list_1-5>li:before{content:"\0025a0   "}.lst-kix_list_1-6>li:before{content:"\0025a0   "}li.li-bullet-0:before{margin-left:-18pt;white-space:nowrap;display:inline-block;min-width:18pt}.lst-kix_list_2-0>li:before{content:"\0025cf   "}.lst-kix_list_2-1>li:before{content:"\0025cb   "}ol.lst-kix_list_6-0.start{counter-reset:lst-ctn-kix_list_6-0 0}.lst-kix_list_1-8>li:before{content:"\0025a0   "}.lst-kix_list_2-2>li:before{content:"\0025a0   "}.lst-kix_list_2-3>li:before{content:"\0025a0   "}ol{margin:0;padding:0}table td,table th{padding:0}.c9{border-right-style:solid;padding:6pt 9pt 6pt 9pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#f8fafd;border-left-style:solid;border-bottom-width:1pt;width:93.6pt;border-top-color:#000000;border-bottom-style:solid}.c17{border-right-style:solid;padding:6pt 9pt 6pt 9pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#f8fafd;border-left-style:solid;border-bottom-width:1pt;width:156pt;border-top-color:#000000;border-bottom-style:solid}.c8{-webkit-text-decoration-skip:none;color:#0000ee;font-weight:400;text-decoration:underline;vertical-align:baseline;text-decoration-skip-ink:none;font-size:12pt;font-family:"Google Sans";font-style:normal}.c13{-webkit-text-decoration-skip:none;color:#0000ee;font-weight:400;text-decoration:underline;text-decoration-skip-ink:none;font-size:12pt;font-family:"Google Sans"}.c3{vertical-align:super;font-size:12pt;font-family:"Google Sans Text";font-style:normal;color:#575b5f;font-weight:400}.c0{margin-left:30pt;padding-top:0pt;padding-bottom:0pt;line-height:1.0;padding-left:0pt;text-align:left}.c26{color:#1b1c1d;font-weight:700;font-size:16pt;font-family:"Google Sans";font-style:normal}.c1{font-size:12pt;font-family:"Google Sans Text";font-style:normal;color:#1b1c1d;font-weight:400}.c7{font-size:12pt;font-family:"Google Sans Text";font-style:italic;color:#1b1c1d;font-weight:400}.c15{color:#1b1c1d;font-weight:700;font-size:12pt;font-family:"Google Sans Text";font-style:normal}.c24{color:#000000;font-weight:400;font-size:11pt;font-family:"Arial";font-style:normal}.c28{color:#1b1c1d;font-weight:700;font-size:15pt;font-family:"Google Sans";font-style:normal}.c31{font-size:10pt;font-family:"Google Sans Text";font-style:italic;color:#1b1c1d;font-weight:400}.c30{font-size:10pt;font-family:"Google Sans Text";font-style:normal;color:#1b1c1d;font-weight:700}.c12{color:#1b1c1d;font-weight:400;font-size:10pt;font-family:"Google Sans Text";font-style:normal}.c33{color:#000000;font-weight:700;font-size:12pt;font-family:"Google Sans";font-style:normal}.c19{color:#1b1c1d;font-weight:700;font-size:12pt;font-family:"Google Sans";font-style:normal}.c2{padding-top:6pt;padding-bottom:6pt;line-height:1.149999976158142;text-align:left}.c21{border-spacing:0;border-collapse:collapse;margin-right:auto}.c22{padding-top:6pt;padding-bottom:12pt;line-height:1.149999976158142;text-align:left}.c32{padding-top:0pt;padding-bottom:12.8pt;line-height:1.0;text-align:left}.c25{padding-top:12pt;padding-bottom:12pt;line-height:1.149999976158142;text-align:left}.c27{padding-top:0pt;padding-bottom:12.8pt;line-height:1.149999976158142;text-align:left}.c20{padding-top:0pt;padding-bottom:0pt;line-height:1.149999976158142;text-align:left}.c6{padding-top:0pt;padding-bottom:12pt;line-height:1.149999976158142;text-align:left}.c14{padding-top:0pt;padding-bottom:6pt;line-height:1.149999976158142;text-align:left}.c34{background-color:#ffffff;max-width:468pt;padding:72pt 72pt 72pt 72pt}.c23{font-size:12pt;font-weight:400;font-family:"Google Sans"}.c4{color:inherit;text-decoration:inherit}.c11{margin-left:23.2pt;padding-left:0pt}.c29{padding:0;margin:0}.c10{text-decoration:none;vertical-align:baseline}.c16{text-decoration:none}.c5{height:0pt}.c18{height:11pt}.title{padding-top:24pt;color:#000000;font-weight:700;font-size:36pt;padding-bottom:6pt;font-family:"Arial";line-height:1.0;page-break-after:avoid;text-align:left}.subtitle{padding-top:18pt;color:#666666;font-size:24pt;padding-bottom:4pt;font-family:"Georgia";line-height:1.0;page-break-after:avoid;font-style:italic;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:12pt;color:#000000;font-weight:700;font-size:24pt;padding-bottom:12pt;font-family:"Arial";line-height:1.0;text-align:left}h2{padding-top:11.2pt;color:#000000;font-weight:700;font-size:18pt;padding-bottom:11.2pt;font-family:"Arial";line-height:1.0;text-align:left}h3{padding-top:12pt;color:#000000;font-weight:700;font-size:14pt;padding-bottom:12pt;font-family:"Arial";line-height:1.0;text-align:left}h4{padding-top:12.8pt;color:#000000;font-weight:700;font-size:12pt;padding-bottom:12.8pt;font-family:"Arial";line-height:1.0;text-align:left}h5{padding-top:12.8pt;color:#000000;font-weight:700;font-size:9pt;padding-bottom:12.8pt;font-family:"Arial";line-height:1.0;text-align:left}h6{padding-top:18pt;color:#000000;font-weight:700;font-size:8pt;padding-bottom:18pt;font-family:"Arial";line-height:1.0;text-align:left}</style></head><body class="c34 doc-content"><p class="c6 c18"><span class="c10 c24"></span></p><h1 class="c14"><span class="c26 c10">Complexity versus Probability: A Comparative Analysis of Simplicity Theory and Bayesian Inference in Cognition and AI</span></h1><p class="c6 c18"><span class="c10 c26"></span></p><p class="c6 c18"><span class="c26 c10"></span></p><h2 class="c14"><span class="c28 c10">Part I: The Algorithmic-Cognitive Framework: Simplicity Theory</span></h2><p class="c6 c18"><span class="c28 c10"></span></p><p class="c6"><span class="c1">Simplicity Theory (ST), developed primarily by Jean-Louis Dessalles, offers a distinctive and powerful framework for understanding a specific yet fundamental aspect of human cognition: the detection of relevance and the experience of surprise.</span><span class="c3">1</span><span class="c1">&nbsp;It posits that the human mind is not merely a passive recipient of information but an active pattern-seeker, exquisitely tuned to identify situations that appear &quot;abnormally simple&quot;.</span><span class="c3">1</span><span class="c1">&nbsp;This theory departs significantly from traditional probabilistic accounts by grounding its core mechanisms in Algorithmic Information Theory (AIT), proposing that what makes an event interesting is not its low probability per se, but a quantifiable drop in its complexity.</span><span class="c3">2</span><span class="c1 c10">&nbsp;By operationalizing abstract concepts from AIT, ST aims to provide a formal, predictive, and descriptive model of cognitive phenomena ranging from conversational narrative to creative insight.</span></p><p class="c6 c18"><span class="c1 c10"></span></p><h3 class="c14"><span class="c19 c10">1.1 Foundations in Algorithmic Information Theory (AIT)</span></h3><p class="c6 c18"><span class="c19 c10"></span></p><p class="c6"><span class="c1">The theoretical bedrock of Simplicity Theory is Algorithmic Information Theory, a field that provides a formal, objective measure of complexity.</span><span class="c3">4</span><span class="c1 c10">&nbsp;Understanding this foundation is essential to grasping the novel claims and mechanisms of ST.</span></p><p class="c6 c18"><span class="c1 c10"></span></p><h4 class="c14"><span class="c19 c10">Core Concept: Kolmogorov Complexity (KC)</span></h4><p class="c6 c18"><span class="c19 c10"></span></p><p class="c6"><span class="c1">At the heart of AIT lies the concept of Kolmogorov Complexity (KC), also known as algorithmic complexity.</span><span class="c3">4</span><span class="c1">&nbsp;The KC of an object, such as a string of text or a sequence of numbers, is defined as the length of the shortest possible computer program, written in a fixed universal programming language, that can produce that object as its output and then halt.</span><span class="c3">4</span><span class="c1">&nbsp;This provides a measure of the computational resources needed to specify the object, effectively quantifying its intrinsic complexity or incompressibility.</span><span class="c3 c16">4</span></p><p class="c6"><span class="c1">For example, a highly patterned string like &quot;abababababababab&quot; can be generated by a very short program (e.g., &quot;print &#39;ab&#39; 8 times&quot;), and thus has a low Kolmogorov Complexity. In contrast, a string that appears random, such as &quot;arfbxgkwdlqpvcz,&quot; contains no discernible regularities that can be exploited for compression. The shortest program to generate it is essentially the program itself (&quot;print &#39;arfbxgkwdlqpvcz&#39;&quot;), meaning its KC is approximately the length of the string itself.</span><span class="c3">6</span><span class="c1">&nbsp;In this view, simplicity is synonymous with compressibility.</span><span class="c3">6</span><span class="c1">&nbsp;This measure is theoretically robust; while the absolute complexity value depends on the choice of programming language, the difference in complexity between two objects is largely independent of the language, differing only by a constant factor.</span><span class="c3 c16">8</span></p><p class="c6 c18"><span class="c3 c16"></span></p><h4 class="c14"><span class="c19 c10">The Incomputability Problem</span></h4><p class="c6 c18"><span class="c19 c10"></span></p><p class="c6"><span class="c1">A profound and well-known challenge within AIT is that Kolmogorov Complexity is, in the general case, an uncomputable function.</span><span class="c3">4</span><span class="c1">&nbsp;Akin to Turing&#39;s halting problem, there exists no general algorithm that can take an arbitrary string as input and output the length of its shortest possible program.</span><span class="c3">4</span><span class="c1 c10">&nbsp;This is because proving that a given program is the</span></p><p class="c6"><span class="c7">shortest</span><span class="c1 c10">&nbsp;would require testing all shorter programs to see if they also produce the same output, and there is no universal way to know if these programs will ever halt. This theoretical obstacle would seem to render KC unusable as a practical foundation for any model of cognition, as the human mind must operate within finite time and with finite resources.</span></p><p class="c6 c18"><span class="c1 c10"></span></p><h4 class="c14"><span class="c19 c10">ST&#39;s Solution: Observer-Dependent, Resource-Bounded Complexity</span></h4><p class="c6 c18"><span class="c19 c10"></span></p><p class="c6"><span class="c1">Simplicity Theory offers a pragmatic and cognitively plausible resolution to the incomputability problem. It posits that the human mind does not and cannot compute the absolute, universal Kolmogorov Complexity of an event.</span><span class="c3">10</span><span class="c1">&nbsp;Instead, it computes a resource-bounded and observer-dependent version of complexity.</span><span class="c3">2</span><span class="c1 c10">&nbsp;This crucial move transforms complexity from an abstract, objective mathematical property into a subjective, psychological one.</span></p><p class="c6"><span class="c1">According to ST, the complexity of a situation is always relative to the descriptive and computational resources available to a specific observer at a specific moment.</span><span class="c3">2</span><span class="c1">&nbsp;The &quot;shortest description&quot; is not the shortest in any universal language, but the shortest one the observer can personally find using their current knowledge, memory, and pattern-matching abilities. This observer-dependency elegantly resolves many paradoxes. For instance, the lottery draw &quot;12-22-27-37-38-42&quot; has a high complexity for a general observer who sees no pattern. However, for the person who played that exact combination, its description complexity is minimal&mdash;it is simply &quot;the numbers I chose&quot;.</span><span class="c3">2</span><span class="c1 c10">&nbsp;This makes the complexity, and thus the entire framework of ST, contingent on the individual&#39;s cognitive state, grounding the theory in psychological reality rather than abstract mathematics.</span></p><p class="c6 c18"><span class="c1 c10"></span></p><h3 class="c14"><span class="c19 c10">1.2 The Core Mechanism: Unexpectedness as Complexity Drop</span></h3><p class="c6 c18"><span class="c19 c10"></span></p><p class="c6"><span class="c1 c10">The central conceptual innovation of Simplicity Theory lies not merely in its application of Kolmogorov Complexity, but in its crucial bifurcation of this concept into two distinct, psychologically meaningful measures: generation complexity and description complexity. This division transforms a monolithic mathematical property into a dynamic, relational model of an observer confronting a world. The discrepancy between these two measures is the engine that drives the theory.</span></p><p class="c6 c18"><span class="c1 c10"></span></p><h4 class="c14"><span class="c19 c10">Formal Definition</span></h4><p class="c6 c18"><span class="c19 c10"></span></p><p class="c6"><span class="c1">ST&#39;s central claim is formalized in its core equation, which defines unexpectedness, U, for a given situation, s, as the difference between its expected complexity and its observed complexity </span><span class="c3">2</span><span class="c1 c10">:</span></p><p class="c20"><span class="c1 c10">U(s)=Cgen&#8203;(s)&minus;Cdesc&#8203;(s)</span></p><p class="c6 c18"><span class="c1 c10"></span></p><h4 class="c14"><span class="c19 c10">Generation Complexity (C_gen)</span></h4><p class="c6 c18"><span class="c19 c10"></span></p><p class="c6"><span class="c1">Generation complexity, Cgen&#8203;(s), represents the observer&#39;s model of the causal complexity of the event s.</span><span class="c3">2</span><span class="c1">&nbsp;It is the length of the minimal description of all the parameters that must be specified in the &quot;world&quot; for the situation to be generated or to come into existence.</span><span class="c3">10</span><span class="c1 c10">&nbsp;In essence,</span></p><p class="c6"><span class="c1">Cgen&#8203; is the agent&#39;s theory of the world&#39;s causal structure&mdash;their best guess at the &quot;true&quot; complexity of the process that produced the event. For a fair lottery drawing six numbers from 49, the generation complexity for any specific sequence is high and roughly equal, as it requires the specification of six independent random draws, amounting to a complexity of approximately 6&times;log2&#8203;(49) bits.</span><span class="c3 c16">3</span></p><p class="c6 c18"><span class="c3 c16"></span></p><h4 class="c14"><span class="c19 c10">Description Complexity (C_desc)</span></h4><p class="c6 c18"><span class="c19 c10"></span></p><p class="c6"><span class="c1">Description complexity, Cdesc&#8203;(s), is the length of the shortest description of the situation s that the observer can mentally construct using their available cognitive resources.</span><span class="c3">2</span><span class="c1 c10">&nbsp;This term represents the observer&#39;s internal cognitive ability to find a pattern or a compact representation of the observed data. For a &quot;random&quot; lottery sequence like &quot;12-22-27-37-38-42,&quot; the observer has no simple rule to describe it, so its</span></p><p class="c6"><span class="c1">Cdesc&#8203; is high, close to its Cgen&#8203;. However, for the sequence &quot;22-23-24-25-26-27,&quot; the observer can easily compress it with a simple rule like &quot;the arithmetic sequence starting at 22,&quot; making its Cdesc&#8203; very low.</span><span class="c3 c16">2</span></p><p class="c6 c18"><span class="c3 c16"></span></p><h4 class="c14"><span class="c19 c10">Unexpectedness (U)</span></h4><p class="c6 c18"><span class="c19 c10"></span></p><p class="c6"><span class="c1">The key output of the theory, unexpectedness (U), is therefore not a measure of absolute simplicity or improbability, but a measure of the </span><span class="c7">discrepancy</span><span class="c1">&nbsp;between the agent&#39;s theory of the world and the agent&#39;s perception of the data. A situation is deemed interesting, relevant, or surprising when it is significantly simpler to describe than the observer&#39;s causal model of the world would lead them to expect (i.e., when Cdesc&#8203;&#8810;Cgen&#8203;).</span><span class="c3">1</span><span class="c1">&nbsp;This &quot;complexity drop&quot; or &quot;randomness deficiency&quot; acts as a powerful cognitive signal.</span><span class="c3">2</span><span class="c1">&nbsp;The human mind, in ST&#39;s view, is a machine exquisitely tuned to detect this difference.</span><span class="c3">3</span><span class="c1 c10">&nbsp;A large positive</span></p><p class="c6"><span class="c1 c10">U is a cognitive alarm bell that signals, &quot;Pay attention, your model of reality might be incomplete or wrong, because this event is too simple to have been generated by the process you assumed.&quot;</span></p><p class="c6 c18"><span class="c1 c10"></span></p><h3 class="c14"><span class="c19 c10">1.3 From Unexpectedness to Subjective Experience</span></h3><p class="c6 c18"><span class="c19 c10"></span></p><p class="c6"><span class="c1 c10">Simplicity Theory leverages the concept of unexpectedness to build a quantitative and predictive model of a wide range of subjective human experiences, moving from abstract complexity to concrete cognitive phenomena.</span></p><p class="c6 c18"><span class="c1 c10"></span></p><h4 class="c14"><span class="c19 c10">Modeling Interest and Relevance</span></h4><p class="c6 c18"><span class="c19 c10"></span></p><p class="c6"><span class="c1">The theory posits that unexpectedness (U) is one of the two primary ingredients of what humans find interesting (the other being emotional intensity).</span><span class="c3">10</span><span class="c1 c10">&nbsp;Events with a high</span></p><p class="c6"><span class="c1">U value are those that capture our attention, are deemed memorable, and are considered worthy of being reported in conversational narratives or news media.</span><span class="c3">3</span><span class="c1 c10">&nbsp;This provides a formal explanation for the &quot;So what?&quot; test of narrative relevance; a story is rejected as uninteresting if it describes an ordinary event where</span></p><p class="c6"><span class="c1">Cgen&#8203;&asymp;Cdesc&#8203; and thus U&asymp;0.</span><span class="c3 c16">12</span></p><p class="c6"><span class="c1">This framework explains why we find coincidences so compelling. Meeting a specific friend by chance in a distant foreign city is a highly unexpected event. The generation complexity is enormous (the product of all the independent choices that led both individuals to that exact spot at that exact time). However, the description complexity is much lower, as the event can be compressed by noting the shared identity of the two people and the single location.</span><span class="c3">12</span><span class="c1 c10">&nbsp;In contrast, meeting a stranger in that same spot is not interesting, because although the generation complexity is equally high, the description complexity is also high (as there is no simple relation to compress), resulting in a low unexpectedness value.</span></p><p class="c6 c18"><span class="c1 c10"></span></p><h4 class="c14"><span class="c19 c10">Defining Subjective Probability</span></h4><p class="c6 c18"><span class="c19 c10"></span></p><p class="c6"><span class="c1">One of the most radical proposals of Simplicity Theory is its redefinition of </span><span class="c7">ex-post</span><span class="c1 c10">&nbsp;subjective probability, p, for a unique event:</span></p><p class="c20"><span class="c1 c10">p=2&minus;U</span></p><p class="c6"><span class="c1">This formulation has several profound implications.</span><span class="c3">1</span><span class="c1">&nbsp;First, it is designed to apply to unique, individual situations, a domain where classical probability theory struggles because the objective probability of any fully instantiated, non-repeatable event is effectively zero.</span><span class="c3">2</span><span class="c1">&nbsp;Second, it allows for the assessment of subjective probability without requiring knowledge of a complete, well-defined space of alternative events, a major departure from the axiomatic requirements of standard probability.</span><span class="c3">2</span><span class="c1">&nbsp;Third, it explains the powerful human intuition that a highly patterned lottery draw like &quot;1, 2, 3, 4, 5, 6&quot; is subjectively less probable than a &quot;random&quot; one, despite both having the same objective probability in a fair draw.</span><span class="c3">2</span><span class="c1 c10">&nbsp;The patterned draw has a large complexity drop (</span></p><p class="c6"><span class="c1 c10">U&gt;0), yielding a low subjective probability, while the random draw has no complexity drop (U&asymp;0), yielding a subjective probability near 1.</span></p><p class="c6"><span class="c1">A notable feature of this definition is that these subjective probabilities are not required to sum to 1 across different outcomes.</span><span class="c3">10</span><span class="c1 c10">&nbsp;Two different, unremarkable lottery draws can both have a subjective probability close to 1. ST argues this is not a flaw, as this constraint only applies to</span></p><p class="c6"><span class="c7">ex-ante</span><span class="c1">&nbsp;objective probabilities, not </span><span class="c7">ex-post</span><span class="c1">&nbsp;assessments of plausibility for individual events.</span><span class="c3 c16">10</span></p><p class="c6 c18"><span class="c3 c16"></span></p><h4 class="c14"><span class="c19 c10">Broad Applications</span></h4><p class="c6 c18"><span class="c19 c10"></span></p><p class="c6"><span class="c1">The explanatory reach of ST extends to a wide array of cognitive domains. It has been applied to model creativity as a search for solutions that provide an unexpected drop in problem complexity.</span><span class="c3">11</span><span class="c1">&nbsp;It has been used to formalize emotional intensity, where the magnitude of an emotion is a function of both unexpectedness and the personal impact of the situation.</span><span class="c3">11</span><span class="c1">&nbsp;Furthermore, ST has been operationalized in artificial intelligence and natural language processing, for instance, to solve word analogies by finding the transformation of minimal complexity or to mine for &quot;intuitive&quot; relational explanations in knowledge bases.</span><span class="c3 c16">1</span></p><p class="c6 c18"><span class="c3 c16"></span></p><h3 class="c14"><span class="c19 c10">1.4 ST as a Descriptive Model of Cognition</span></h3><p class="c6 c18"><span class="c19 c10"></span></p><p class="c6"><span class="c1">It is crucial to position Simplicity Theory within the broader landscape of cognitive modeling. Its primary contribution and philosophical stance is that of a </span><span class="c7">descriptive</span><span class="c1 c10">&nbsp;theory of cognition.</span></p><p class="c6 c18"><span class="c1 c10"></span></p><h4 class="c14"><span class="c19 c10">Focus on &quot;How&quot; vs. &quot;Should&quot;</span></h4><p class="c6 c18"><span class="c19 c10"></span></p><p class="c6"><span class="c1">Unlike normative theories that prescribe how a perfectly rational agent </span><span class="c7">should</span><span class="c1">&nbsp;think, ST&#39;s primary goal is to characterize and explain the actual, observable regularities of human thought.</span><span class="c3">15</span><span class="c1">&nbsp;It seeks to model the cognitive mechanisms underlying the human faculty for detecting relevance, generating surprise, and structuring narratives.</span><span class="c3">11</span><span class="c1 c10">&nbsp;Its aim is to answer the question &quot;How do human minds find things interesting?&quot; rather than &quot;What is the most rational way to process information?&quot;.</span></p><p class="c6 c18"><span class="c1 c10"></span></p><h4 class="c14"><span class="c19 c10">An Alternative to Probabilistic Accounts</span></h4><p class="c6 c18"><span class="c19 c10"></span></p><p class="c6"><span class="c1">ST is often presented as a direct challenge to the sufficiency of purely probabilistic models for explaining human interest.</span><span class="c3">11</span><span class="c1">&nbsp;Proponents argue that frameworks based on Shannon&#39;s information theory or Bayesian inference fail to capture the special cognitive status of events that are simple but improbable (like the patterned lottery draw) or deterministic yet surprising (like a predictable lunar eclipse, which is surprising to someone unaware of celestial mechanics).</span><span class="c3">11</span><span class="c1 c10">&nbsp;In these cases, the objective probability may be known, but the cognitive experience of surprise is driven by the perceived complexity drop. This suggests that a complexity-based metric may be more fundamental to human intuition than a purely probabilistic one in these specific contexts.</span></p><p class="c6 c18"><span class="c1 c10"></span></p><h4 class="c14"><span class="c19 c10">Falsifiable Predictions</span></h4><p class="c6 c18"><span class="c19 c10"></span></p><p class="c6"><span class="c1">Despite its descriptive nature, a key strength of ST is that it is not merely a &quot;just-so story&quot; or a post-hoc rationalization. By defining unexpectedness quantitatively, the theory makes concrete, falsifiable predictions about which events people will find interesting, memorable, and worth communicating.</span><span class="c3">3</span><span class="c1">&nbsp;For example, it predicts that the interestingness of a coincidence increases with the complexity of the shared feature and decreases with the simplicity of the context (e.g., meeting a friend is more surprising in a large, distant city than in one&#39;s small hometown).</span><span class="c3">3</span><span class="c1 c10">&nbsp;This commitment to quantitative prediction lends the theory scientific rigor and distinguishes it from purely qualitative accounts of cognition.</span></p><p class="c6 c18"><span class="c1 c10"></span></p><h2 class="c14"><span class="c28 c10">Part II: The Probabilistic-Inferential Framework: Bayesian Model Inference</span></h2><p class="c6 c18"><span class="c28 c10"></span></p><p class="c6"><span class="c1">In stark contrast to the algorithmic-cognitive approach of Simplicity Theory, Bayesian inference provides a comprehensive framework for reasoning and learning under uncertainty, rooted entirely in the axioms of probability theory.</span><span class="c3">18</span><span class="c1 c10">&nbsp;While often introduced as a simple rule for updating probabilities, its true power lies in its application as a complete system for model comparison and selection. This system gives rise to an emergent principle of parsimony, known as the Bayesian Occam&#39;s Razor, which serves as the primary point of comparison with the complexity-based principles of Simplicity Theory.</span></p><p class="c6 c18"><span class="c1 c10"></span></p><h3 class="c14"><span class="c19 c10">2.1 Foundations in Probability Theory</span></h3><p class="c6 c18"><span class="c19 c10"></span></p><p class="c6"><span class="c1 c10">The Bayesian framework is built upon a specific interpretation of probability and a single, powerful theorem that serves as its core inferential engine.</span></p><p class="c6 c18"><span class="c1 c10"></span></p><h4 class="c14"><span class="c19 c10">The Bayesian Interpretation of Probability</span></h4><p class="c6 c18"><span class="c19 c10"></span></p><p class="c6"><span class="c1">The Bayesian paradigm interprets probability not as a long-run frequency of an event in repeated trials (the frequentist view), but as a subjective &quot;degree of belief&quot; or confidence that an individual holds about the truth of a proposition.</span><span class="c3">20</span><span class="c1">&nbsp;A probability of 1 represents absolute certainty that a proposition is true, a probability of 0 represents absolute certainty that it is false, and values in between represent graded levels of confidence.</span><span class="c3">20</span><span class="c1">&nbsp;The central tenet of Bayesianism is that it is rational to update these degrees of belief as new evidence becomes available.</span><span class="c3">19</span><span class="c1 c10">&nbsp;This subjective interpretation is fundamental, as it allows probabilities to be assigned to hypotheses (e.g., &quot;the probability that this coin is biased&quot;) and not just to the outcomes of random events.</span></p><p class="c6 c18"><span class="c1 c10"></span></p><h4 class="c14"><span class="c19 c10">The Core Machinery: Bayes&#39; Theorem for Model Inference</span></h4><p class="c6 c18"><span class="c19 c10"></span></p><p class="c6"><span class="c1">The mechanism for rational belief updating is Bayes&#39; theorem. When applied to the problem of comparing different models or hypotheses in light of data, the theorem is expressed as follows </span><span class="c3">19</span><span class="c1 c10">:</span></p><p class="c20"><span class="c1 c10">P(H&#8739;D)=P(D)P(D&#8739;H)&times;P(H)&#8203;</span></p><p class="c14"><span class="c1 c10">Each component of this equation plays a distinct and crucial role in the inferential process:</span></p><ul class="c29 lst-kix_list_1-0 start"><li class="c14 c11 li-bullet-0"><span class="c15">Prior Probability, P(H):</span><span class="c1">&nbsp;The prior represents the initial degree of belief in a hypothesis, H, </span><span class="c7">before</span><span class="c1">&nbsp;any data, D, has been observed.</span><span class="c3">18</span><span class="c1">&nbsp;This term allows for the principled incorporation of existing knowledge, assumptions, or experience into the model. For example, in a clinical trial, one might assign a prior belief that a new drug is unlikely to have a large effect.</span><span class="c3">22</span><span class="c1 c10">&nbsp;The choice of prior is a critical and sometimes contentious aspect of Bayesian modeling.</span></li><li class="c2 c11 li-bullet-0"><span class="c15">Likelihood, P(D&#8739;H):</span><span class="c1">&nbsp;The likelihood function is the bridge that connects an abstract hypothesis to concrete data. It quantifies the probability of observing the specific data D </span><span class="c7">if</span><span class="c1">&nbsp;the hypothesis H were true.</span><span class="c3">22</span><span class="c1">&nbsp;For example, if the hypothesis is &quot;this coin is fair&quot; (</span><span class="c24 c10"><br></span><span class="c1 c10">H), the likelihood of observing 7 heads in 10 tosses (D) can be calculated directly from the binomial distribution.</span></li><li class="c2 c11 li-bullet-0"><span class="c15">Posterior Probability, P(H&#8739;D):</span><span class="c1">&nbsp;The posterior is the ultimate output of the inference. It represents the updated, revised degree of belief in the hypothesis H </span><span class="c7">after</span><span class="c1">&nbsp;the evidence D has been taken into account.</span><span class="c3">18</span><span class="c1">&nbsp;It is a rational synthesis of the prior belief and the information contained in the data. This posterior can then serve as the prior for a subsequent round of belief updating when new data arrives.</span><span class="c3 c16">20</span></li><li class="c2 c11 li-bullet-0"><span class="c15">Evidence (or Marginal Likelihood), P(D):</span><span class="c1">&nbsp;This term, often treated as a mere normalizing constant in simple parameter estimation problems, is the absolute key to Bayesian model selection.</span><span class="c3">18</span><span class="c1">&nbsp;The evidence represents the total probability of the observed data, calculated by averaging the likelihood over all possible hypotheses (or all possible parameter values within a model), weighted by their respective prior probabilities.</span><span class="c3">24</span><span class="c1">&nbsp;Formally, for a model with parameters</span><span class="c24 c10"><br></span><span class="c1">&theta;:</span><span class="c24 c10"><br></span><span class="c1">P(D)=&int;P(D&#8739;&theta;,H)P(&theta;&#8739;H)d&theta;</span><span class="c24 c10"><br></span><span class="c1">This integral evaluates the </span><span class="c7">average</span><span class="c1 c10">&nbsp;predictive performance of the model H across its entire parameter space, not just its performance at the single best-fitting parameter value. As will be shown, this averaging property is the source of the Bayesian Occam&#39;s Razor.</span></li></ul><p class="c25 c18"><span class="c1 c10"></span></p><h3 class="c14"><span class="c19 c10">2.2 The Bayesian Occam&#39;s Razor: An Emergent Principle of Parsimony</span></h3><p class="c6 c18"><span class="c19 c10"></span></p><p class="c6"><span class="c1">One of the most elegant and powerful features of Bayesian model selection is that it provides an automatic, quantitative preference for simpler models without needing to add an explicit penalty term for complexity. This &quot;Bayesian Occam&#39;s Razor&quot; is not an ad-hoc addition but an emergent property of the model evidence, P(D).</span><span class="c3">25</span><span class="c1 c10">&nbsp;The penalty is not for a model&#39;s</span></p><p class="c6"><span class="c7">syntactic complexity</span><span class="c1">&nbsp;(e.g., the length of its formula), but for its </span><span class="c7">semantic flexibility</span><span class="c1 c10">&mdash;its capacity to explain too many different outcomes. A model is punished not for being long-winded, but for being non-committal.</span></p><p class="c6 c18"><span class="c1 c10"></span></p><h4 class="c14"><span class="c19 c10">The Problem of Overfitting</span></h4><p class="c6 c18"><span class="c19 c10"></span></p><p class="c6"><span class="c1">A fundamental challenge in all of statistical modeling is overfitting.</span><span class="c3">28</span><span class="c1">&nbsp;A more complex model (e.g., a high-degree polynomial for curve fitting) can always achieve a better fit to a given set of data points than a simpler model. However, this superior fit often comes at the cost of capturing random noise in the data rather than the true underlying signal. As a result, the overfitted model will make poor predictions for new, unseen data.</span><span class="c3">28</span><span class="c1">&nbsp;The principle of parsimony, or Occam&#39;s Razor, is the heuristic that we should prefer the simplest explanation that adequately fits the data.</span><span class="c3 c16">28</span></p><p class="c6 c18"><span class="c3 c16"></span></p><h4 class="c14"><span class="c19 c10">How the Evidence P(D) Automatically Penalizes Complexity</span></h4><p class="c6 c18"><span class="c19 c10"></span></p><p class="c6"><span class="c1">The Bayesian framework provides a formal, mathematical justification for this heuristic. The mechanism operates through the model evidence, P(D). A complex model, by virtue of having more parameters or parameters with wider ranges, is inherently more flexible. It is capable of generating or &quot;predicting&quot; a much wider variety of possible datasets.</span><span class="c3">25</span><span class="c1">&nbsp;However, any probabilistic model is governed by what has been called the &quot;Law of Conservation of Belief&quot;: the total probability it can assign across all possible datasets must sum to one.</span><span class="c3 c16">28</span></p><p class="c6"><span class="c1">This constraint forces a complex model to &quot;spread its predictive probability more thinly&quot; over the vast space of data it could potentially explain.</span><span class="c3">25</span><span class="c1">&nbsp;In contrast, a simpler model, being less flexible, makes more specific, concentrated predictions, focusing its probability mass on a much smaller range of possible datasets.</span><span class="c3 c16">25</span></p><p class="c6 c18"><span class="c3 c16"></span></p><h4 class="c14"><span class="c19 c10">The &quot;Occam Factor&quot;</span></h4><p class="c6 c18"><span class="c19 c10"></span></p><p class="c6"><span class="c1">As a result of this dynamic, when a specific dataset D is observed that both a simple model (H1&#8203;) and a complex model (H2&#8203;) can explain, the simple model will almost always have assigned a higher average probability to that dataset. The model evidence, P(D&#8739;H1&#8203;), will be greater than P(D&#8739;H2&#8203;). This is because the complex model &quot;wasted&quot; much of its prior belief on predicting other datasets that did not end up occurring.</span><span class="c3 c16">28</span></p><p class="c6"><span class="c1">This effect can be formalized by approximating the evidence as the product of the best-fit likelihood and an &quot;Occam factor&quot; </span><span class="c3">25</span><span class="c1 c10">:</span></p><p class="c20"><span class="c1 c10">P(D&#8739;H)&asymp;P(D&#8739;wMP&#8203;,H)&times;&sigma;w&#8203;&sigma;w&#8739;D&#8203;&#8203;</span></p><p class="c6"><span class="c1">Here, P(D&#8739;wMP&#8203;,H) is the likelihood at the best-fitting (maximum posterior) parameters. The second term is the Occam factor, where &sigma;w&#8203; is the prior uncertainty over the parameters and &sigma;w&#8739;D&#8203; is the posterior uncertainty after seeing the data.</span><span class="c3">25</span><span class="c1 c10">&nbsp;A complex model starts with a large prior uncertainty (</span></p><p class="c6"><span class="c1">&sigma;w&#8203;) and thus is penalized more heavily. The evidence naturally favors models that are not only accurate (high best-fit likelihood) but also predictive and parsimonious (a large Occam factor). The ratio of the evidence values for two competing models, P(D&#8739;H1&#8203;)/P(D&#8739;H2&#8203;), which is known as the Bayes Factor, directly quantifies the extent to which the data support the simpler model over the more complex one, thus implementing an &quot;automatic Occam&#39;s Razor&quot;.</span><span class="c3 c16">27</span></p><p class="c6 c18"><span class="c3 c16"></span></p><h3 class="c14"><span class="c19 c10">2.3 Bayesianism as a Normative and Descriptive Framework</span></h3><p class="c6 c18"><span class="c19 c10"></span></p><p class="c6"><span class="c1 c10">The Bayesian framework holds a unique dual status in cognitive science, serving as both a benchmark for ideal rationality and a descriptive model of actual mental processes.</span></p><p class="c6 c18"><span class="c1 c10"></span></p><h4 class="c14"><span class="c19 c10">The Normative Standard</span></h4><p class="c6 c18"><span class="c19 c10"></span></p><p class="c6"><span class="c1">At its core, Bayesian inference is a </span><span class="c7">normative</span><span class="c1">&nbsp;theory.</span><span class="c3">15</span><span class="c1 c10">&nbsp;It provides a set of mathematically coherent and provably optimal rules for how a rational agent</span></p><p class="c6"><span class="c7">should</span><span class="c1">&nbsp;update their beliefs and make decisions in the face of uncertainty. It is a theory of ideal reasoning, grounded in the axioms of probability theory as laid down by figures like Andrey Kolmogorov.</span><span class="c3">19</span><span class="c1 c10">&nbsp;Philosophers and statisticians appeal to this normative status to argue that it is the correct way to conduct scientific inference.</span></p><p class="c6 c18"><span class="c1 c10"></span></p><h4 class="c14"><span class="c19 c10">The Descriptive Turn: The &quot;Bayesian Brain&quot; Hypothesis</span></h4><p class="c6 c18"><span class="c19 c10"></span></p><p class="c6"><span class="c1">Beginning in the late 20th century, a paradigm shift occurred in cognitive science, where this normative framework was increasingly adopted as a </span><span class="c7">descriptive</span><span class="c1">&nbsp;model of the mind.</span><span class="c3">31</span><span class="c1">&nbsp;The &quot;Bayesian Brain&quot; hypothesis posits that the brain&#39;s fundamental computations are inherently Bayesian.</span><span class="c3">32</span><span class="c1">&nbsp;This perspective suggests that neural systems, from low-level perception and motor control to high-level reasoning and language, are constantly performing probabilistic inference to contend with the sparse, noisy, and ambiguous nature of sensory input.</span><span class="c3">31</span><span class="c1">&nbsp;For example, the perceptual system is thought to execute an unconscious Bayesian inference, combining prior knowledge about the world with incoming sensory data to form a stable and reliable perception of the environment.</span><span class="c3 c16">32</span></p><p class="c6 c18"><span class="c3 c16"></span></p><h4 class="c14"><span class="c19 c10">The Is-Ought Duality</span></h4><p class="c6 c18"><span class="c19 c10"></span></p><p class="c6"><span class="c1">This dual status is one of the most powerful and debated aspects of Bayesian cognitive science. The framework is used simultaneously to define &quot;optimal&quot; performance on a cognitive task and to describe the &quot;actual&quot; performance of human subjects.</span><span class="c3">34</span><span class="c1">&nbsp;When human behavior aligns with the Bayesian model, it is often interpreted as evidence that the mind is an &quot;optimal&quot; information processor. When behavior deviates, these discrepancies can be analyzed to understand the specific heuristics or biases at play.</span><span class="c3">34</span><span class="c1 c10">&nbsp;This creates a powerful but sometimes conceptually blurry link between the &quot;is&quot; of human cognition and the &quot;ought&quot; of rational inference, making Bayesianism a uniquely versatile tool for studying the mind.</span></p><p class="c6 c18"><span class="c1 c10"></span></p><h2 class="c14"><span class="c28 c10">Part III: A Comparative Synthesis: Algorithmic Complexity vs. Bayesian Probability</span></h2><p class="c6 c18"><span class="c28 c10"></span></p><p class="c6"><span class="c1 c10">Having established the distinct foundations and mechanisms of Simplicity Theory and Bayesian inference, a direct comparative analysis reveals their deep-seated differences, surprising points of convergence, and complementary explanatory strengths. This synthesis moves beyond a surface-level description to a critical evaluation of their relationship, using the Minimum Description Length (MDL) principle as a crucial conceptual bridge.</span></p><p class="c6 c18"><span class="c1 c10"></span></p><h3 class="c14"><span class="c19 c10">3.1 Foundational Axioms: A Tale of Two Theories</span></h3><p class="c6 c18"><span class="c19 c10"></span></p><p class="c6"><span class="c1 c10">The most fundamental divergence between the two frameworks lies in their axiomatic origins and the primary objects of their analysis. This initial comparison is best summarized in a structured format before delving into the detailed arguments.</span></p><hr><p class="c22"><span class="c15 c10">Table 1: Foundational Comparison of Simplicity Theory and Bayesian Inference</span></p><p class="c20 c18"><span class="c15 c10"></span></p><table class="c21"><tr class="c5"><td class="c17" colspan="1" rowspan="1"><p class="c2"><span class="c12 c10">Feature</span></p></td><td class="c17" colspan="1" rowspan="1"><p class="c2"><span class="c12 c10">Simplicity Theory (ST)</span></p></td><td class="c17" colspan="1" rowspan="1"><p class="c2"><span class="c12 c10">Bayesian Model Inference</span></p></td></tr><tr class="c5"><td class="c17" colspan="1" rowspan="1"><p class="c2"><span class="c30 c10">Theoretical Foundation</span></p></td><td class="c17" colspan="1" rowspan="1"><p class="c20"><span class="c12">Algorithmic Information Theory (AIT) </span><span class="c3 c16">1</span></p></td><td class="c17" colspan="1" rowspan="1"><p class="c20"><span class="c12">Probability Theory </span><span class="c3 c16">18</span></p></td></tr><tr class="c5"><td class="c17" colspan="1" rowspan="1"><p class="c2"><span class="c30 c10">Core Metric</span></p></td><td class="c17" colspan="1" rowspan="1"><p class="c20"><span class="c12">Unexpectedness (U): A complexity drop </span><span class="c3 c16">2</span></p></td><td class="c17" colspan="1" rowspan="1"><p class="c2"><span class="c12 c10">Posterior Probability ($P(H</span></p></td></tr><tr class="c5"><td class="c17" colspan="1" rowspan="1"><p class="c2"><span class="c30 c10">Object of Analysis</span></p></td><td class="c17" colspan="1" rowspan="1"><p class="c20"><span class="c12">Unique, individual events (s) </span><span class="c3 c16">10</span></p></td><td class="c17" colspan="1" rowspan="1"><p class="c20"><span class="c12">Distributions over hypotheses/parameters (H) </span><span class="c3 c16">24</span></p></td></tr><tr class="c5"><td class="c17" colspan="1" rowspan="1"><p class="c2"><span class="c30 c10">Treatment of Simplicity</span></p></td><td class="c17" colspan="1" rowspan="1"><p class="c20"><span class="c12">Direct calculation: U=Cgen&#8203;&minus;Cdesc&#8203; </span><span class="c3 c16">3</span></p></td><td class="c17" colspan="1" rowspan="1"><p class="c20"><span class="c12">Emergent property: Penalty via model evidence P(D) </span><span class="c3 c16">25</span></p></td></tr><tr class="c5"><td class="c17" colspan="1" rowspan="1"><p class="c2"><span class="c30 c10">Primary Stance</span></p></td><td class="c17" colspan="1" rowspan="1"><p class="c20"><span class="c12">Descriptive: How minds find things interesting </span><span class="c3 c16">11</span></p></td><td class="c17" colspan="1" rowspan="1"><p class="c20"><span class="c12">Normative: How beliefs </span><span class="c31">should</span><span class="c12">&nbsp;be updated </span><span class="c3 c16">16</span></p></td></tr><tr class="c5"><td class="c17" colspan="1" rowspan="1"><p class="c2"><span class="c30 c10">Key Challenge</span></p></td><td class="c17" colspan="1" rowspan="1"><p class="c20"><span class="c12">Incomputability of KC; relies on observer-bounded approximations </span><span class="c3 c16">4</span></p></td><td class="c17" colspan="1" rowspan="1"><p class="c20"><span class="c12">Requires well-defined, measurable space of events; choice of prior </span><span class="c3 c16">13</span></p></td></tr></table><hr><p class="c22 c18"><span class="c3 c16"></span></p><h4 class="c14"><span class="c19 c10">ST&#39;s Critique of Probability</span></h4><p class="c6 c18"><span class="c19 c10"></span></p><p class="c6"><span class="c1">Simplicity Theory&#39;s departure from probability theory is not incidental; it is a core part of its motivation. Proponents of ST argue that the axioms of standard probability theory are fundamentally ill-suited for modeling key aspects of human cognition.</span><span class="c3">13</span><span class="c1">&nbsp;A primary objection is the requirement of a pre-defined, measurable space of events. This axiom assumes that all possible outcomes can be enumerated in a well-behaved set, which is often not representative of how humans flexibly and dynamically construct concepts and event spaces on the fly.</span><span class="c3">13</span><span class="c1">&nbsp;Furthermore, ST claims that probability theory, on its own, cannot adequately explain the cognitive experience of surprise in certain situations. For example, a deterministic event like a predictable lunar eclipse can still be highly surprising to an observer who lacks the correct causal model. Similarly, a highly patterned lottery draw like &quot;1,1,1,1,1,1&quot; is perceived as more surprising and less subjectively probable than a random-looking one, even when their objective probabilities are identical.</span><span class="c3">13</span><span class="c1 c10">&nbsp;ST argues that in these cases, the cognitive signal is driven by a complexity drop, not by probability.</span></p><p class="c6 c18"><span class="c1 c10"></span></p><h4 class="c14"><span class="c19 c10">Bayesian Critique of AIT/ST</span></h4><p class="c6 c18"><span class="c19 c10"></span></p><p class="c6"><span class="c1">Conversely, from a Bayesian perspective, the foundation of ST appears less rigorous. The primary critique centers on ST&#39;s reliance on Kolmogorov Complexity, a theoretically incomputable measure.</span><span class="c3">4</span><span class="c1">&nbsp;While ST&#39;s solution of using an &quot;observer-dependent, resource-bounded&quot; complexity is cognitively plausible, it introduces a degree of subjectivity that can seem ad-hoc from the standpoint of a formal theory.</span><span class="c3">10</span><span class="c1">&nbsp;The choice of what constitutes an observer&#39;s &quot;available descriptions&quot; and &quot;computational operations&quot; is not axiomatized and could be difficult to specify and constrain a priori. This contrasts sharply with the rigorous, axiomatic foundation of modern probability theory, which was, ironically, co-developed by Andrey Kolmogorov himself.</span><span class="c3">19</span><span class="c1 c10">&nbsp;To a Bayesian, the subjective choice of a prior distribution, while challenging, is arguably more transparent and formally constrained than the subjective choice of a descriptive language in ST.</span></p><p class="c6 c18"><span class="c1 c10"></span></p><h4 class="c14"><span class="c19 c10">The &quot;Unique Event&quot; vs. &quot;Distribution&quot; Problem</span></h4><p class="c6 c18"><span class="c19 c10"></span></p><p class="c6"><span class="c1">Perhaps the most profound and clarifying distinction between the two frameworks is their primary explanatory target. Simplicity Theory is fundamentally a theory of </span><span class="c7">single-instance salience</span><span class="c1">. It is designed to explain why a specific, unique, non-repeatable event (s) captures human attention and is deemed interesting or memorable.</span><span class="c3">10</span><span class="c1 c10">&nbsp;Its core mechanism,</span></p><p class="c6"><span class="c1 c10">U=Cgen&#8203;&minus;Cdesc&#8203;, is a post-hoc analysis of the properties of a single, already-observed event.</span></p><p class="c6"><span class="c1">In stark contrast, Bayesian inference is a theory of </span><span class="c7">model-based generalization from data streams</span><span class="c1">. It is designed to update our beliefs about the underlying generative processes (H) that produce data over time.</span><span class="c3">19</span><span class="c1 c10">&nbsp;Its core mechanism, Bayes&#39; theorem, is an engine for learning about distributions and making predictions about future events. ST explains the &quot;Aha!&quot; moment; Bayesianism explains the process of learning. This difference in their primary object of analysis&mdash;a unique event versus a distribution over hypotheses&mdash;is not a minor technicality but a deep conceptual divide that dictates their respective domains of applicability.</span></p><p class="c6 c18"><span class="c1 c10"></span></p><h3 class="c14"><span class="c19 c10">3.2 Re-examining Occam&#39;s Razor: Two Paths to Simplicity</span></h3><p class="c6 c18"><span class="c19 c10"></span></p><p class="c6"><span class="c1 c10">The apparent chasm between Simplicity Theory&#39;s direct, subtractive calculation of complexity and Bayesianism&#39;s emergent, probabilistic penalty for complexity is elegantly bridged by the Minimum Description Length (MDL) principle. This reveals that both frameworks are ultimately striving for the same goal&mdash;parsimonious explanation&mdash;but are approaching it through different, though formally related, mathematical languages.</span></p><p class="c6 c18"><span class="c1 c10"></span></p><h4 class="c14"><span class="c19 c10">The Minimum Description Length (MDL) Principle as a Bridge</span></h4><p class="c6 c18"><span class="c19 c10"></span></p><p class="c6"><span class="c1">The MDL principle provides a formal, information-theoretic statement of Occam&#39;s Razor: the best hypothesis to explain a set of data is the one that permits the greatest compression of the data.</span><span class="c3">5</span><span class="c1 c10">&nbsp;This is typically formulated as a &quot;two-part code,&quot; where the total description length,</span></p><p class="c6"><span class="c1">L(D), for a dataset D using a model or hypothesis H, is the sum of the length of the description of the model itself, L(H), and the length of the description of the data encoded </span><span class="c7">with the help of</span><span class="c1">&nbsp;the model, L(D&#8739;H) </span><span class="c3">9</span><span class="c1 c10">:</span></p><p class="c20"><span class="c1 c10">L(D)=L(H)+L(D&#8739;H)</span></p><p class="c6"><span class="c1">The goal of MDL-based inference is to find the hypothesis H that minimizes this total codelength. This naturally trades off model complexity (a more complex model requires a longer description L(H)) with goodness-of-fit (a model that fits well allows for a shorter description of the data&#39;s deviations, L(D&#8739;H)).</span><span class="c3 c16">36</span></p><p class="c6 c18"><span class="c3 c16"></span></p><h4 class="c14"><span class="c19 c10">Connecting MDL to Bayesianism</span></h4><p class="c6 c18"><span class="c19 c10"></span></p><p class="c6"><span class="c1">The pivotal connection between MDL and Bayesian inference comes from Shannon&#39;s source coding theorem, which establishes a fundamental relationship between probability and optimal codelength: the most efficient code for an event x with probability P(x) has a length of approximately &minus;log2&#8203;P(x) bits.</span><span class="c3 c16">8</span></p><p class="c6"><span class="c1">Applying this equivalence to the Bayesian objective of maximizing the posterior probability, P(H&#8739;D), reveals a deep connection. Maximizing P(H&#8739;D) is equivalent to maximizing its logarithm, logP(H&#8739;D). From Bayes&#39; rule, P(H&#8739;D)&prop;P(H)P(D&#8739;H). Therefore, maximizing the posterior is equivalent to maximizing log(P(H)P(D&#8739;H))=logP(H)+logP(D&#8739;H). Minimizing the </span><span class="c7">negative</span><span class="c1">&nbsp;of this quantity, &minus;logP(H)&minus;logP(D&#8739;H), is mathematically analogous to minimizing the MDL two-part codelength L(H)+L(D&#8739;H).</span><span class="c3 c16">37</span></p><p class="c6"><span class="c1">This demonstrates that Bayesian model selection can be interpreted as a probabilistic method for finding the most compact description of the data.</span><span class="c3">38</span><span class="c1 c10">&nbsp;The Bayesian Occam&#39;s Razor is the probabilistic shadow of this complexity-based principle. This reframes the debate: it is not simply &quot;complexity vs. probability,&quot; but a more nuanced comparison of different formalizations of the same deep principle of parsimony.</span></p><p class="c6 c18"><span class="c1 c10"></span></p><h4 class="c14"><span class="c19 c10">Connecting MDL to ST</span></h4><p class="c6 c18"><span class="c19 c10"></span></p><p class="c6"><span class="c1">While ST&#39;s formula U=Cgen&#8203;&minus;Cdesc&#8203; is not identical to the MDL two-part code, both are born from the same AIT philosophy that equates learning and understanding with compression. MDL provides the crucial insight that the Bayesian preference for simplicity and the complexity-based preference of ST are not alien concepts. Under certain theoretical conditions, such as the use of a &quot;universal prior&quot; where the prior probability of a hypothesis is determined by its Kolmogorov complexity (P(H)&asymp;2&minus;K(H)), Bayesian inference and MDL become formally equivalent.</span><span class="c3">39</span><span class="c1 c10">&nbsp;This establishes a formal link, showing that both frameworks can be seen as different approaches to the same fundamental problem of finding simple, regular patterns in a complex world.</span></p><p class="c6 c18"><span class="c1 c10"></span></p><h3 class="c14"><span class="c19 c10">3.3 Is Bayes&#39; Rule a Special Case of Simplicity Theory?</span></h3><p class="c6 c18"><span class="c19 c10"></span></p><p class="c6"><span class="c1">A provocative hypothesis, advanced by Dessalles and Sileno, suggests that the relationship is not one of parallel approaches but of hierarchy: that Bayes&#39; rule can be viewed as a specific instance of a more general inferential template provided by ST&#39;s unexpectedness formula.</span><span class="c3">13</span><span class="c1 c10">&nbsp;This claim merits careful and critical examination.</span></p><p class="c6 c18"><span class="c1 c10"></span></p><h4 class="c14"><span class="c19 c10">The Dessalles-Sileno Conjecture</span></h4><p class="c6 c18"><span class="c19 c10"></span></p><p class="c6"><span class="c1 c10">The conjecture starts by taking the logarithmic form of Bayes&#39; rule and attempting to map its components onto complexity-based terms from ST. The goal is to show that the probabilistic relationships in Bayesian inference can be reconstructed using the calculus of complexity differences. The proposed mapping is summarized in the table below.</span></p><hr><p class="c22"><span class="c10 c15">Table 2: An Analytical Mapping of Bayesian Terms to Simplicity Theory Concepts</span></p><p class="c20 c18"><span class="c15 c10"></span></p><table class="c21"><tr class="c5"><td class="c9" colspan="1" rowspan="1"><p class="c2"><span class="c12 c10">Bayesian Term</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c2"><span class="c10 c12">ST Concept / Mapping</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c2"><span class="c12 c10">Mathematical Formulation (Bayes)</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c2"><span class="c12 c10">Mathematical Formulation (ST)</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c2"><span class="c12 c10">Notes / Critique</span></p></td></tr><tr class="c5"><td class="c9" colspan="1" rowspan="1"><p class="c2"><span class="c30">Posterior</span><span class="c12 c10">&nbsp;$P(M</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c2"><span class="c12 c10">O)$</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c2"><span class="c30">Plausibility</span><span class="c12 c10">&nbsp;2&minus;U</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c2"><span class="c12 c10">$\frac{P(O</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c2"><span class="c12 c10">M)P(M)}{P(O)}$</span></p></td></tr><tr class="c5"><td class="c9" colspan="1" rowspan="1"><p class="c2"><span class="c30">Likelihood</span><span class="c12 c10">&nbsp;$P(O</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c2"><span class="c12 c10">M)$</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c2"><span class="c30">Likelihood Complexity</span><span class="c12 c10">&nbsp;2&minus;CL&#8203;</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c2"><span class="c12 c10">$\int P(O</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c2"><span class="c12 c10">\theta,M)P(\theta</span></p></td></tr><tr class="c5"><td class="c9" colspan="1" rowspan="1"><p class="c2"><span class="c30">Prior</span><span class="c12 c10">&nbsp;P(M)</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c2"><span class="c30">Prior Complexity</span><span class="c12 c10">&nbsp;2&minus;CM&#8203;</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c2"><span class="c12 c10">P(M)</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c2"><span class="c12 c10">CM&#8203;=Cw&#8203;(c) (Complexity to generate the cause c)</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c20"><span class="c12">This maps the prior probability of a model to the causal complexity of a specific cause, which is a significant conceptual leap.</span><span class="c3 c16">17</span></p></td></tr><tr class="c5"><td class="c9" colspan="1" rowspan="1"><p class="c2"><span class="c30">Evidence</span><span class="c12 c10">&nbsp;P(O)</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c2"><span class="c30">Environmental Complexity</span><span class="c12 c10">&nbsp;2&minus;CE&#8203;</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c2"><span class="c12 c10">$\int P(O</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c2"><span class="c12 c10">M)P(M)dM$</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c2"><span class="c12 c10">CE&#8203;=Cw&#8203;(s) (Total causal complexity of the situation)</span></p></td></tr></table><hr><p class="c22 c18"><span class="c12 c10"></span></p><h4 class="c14"><span class="c19 c10">Analyzing the Proposed Mapping</span></h4><p class="c6 c18"><span class="c19 c10"></span></p><p class="c6"><span class="c1 c10">A rigorous analysis of this mapping reveals several significant conceptual difficulties that challenge the claim of direct subsumption.</span></p><p class="c6"><span class="c1">First, there is a fundamental mismatch in the objects being analyzed. The Bayesian posterior, P(M&#8739;O), is a measure of belief in a </span><span class="c7">model</span><span class="c1">&nbsp;(M) given an observation (O). ST&#39;s core metric, U(s), is a measure of the unexpectedness of a </span><span class="c7">situation</span><span class="c1">&nbsp;(s) itself.</span><span class="c3">13</span><span class="c1 c10">&nbsp;The mapping requires equating the situation</span></p><p class="c6"><span class="c1 c10">s with the observation O, but then must find a counterpart for the model M within ST&#39;s framework, which is not naturally present.</span></p><p class="c6"><span class="c1">Second, to make the mapping work, the proponents must introduce new, derived complexity measures that are not part of the original, parsimonious formulation of ST. For example, a &quot;likelihood complexity&quot; (CL&#8203;) is defined as the complexity to generate an effect from a cause.</span><span class="c3">17</span><span class="c1 c10">&nbsp;This suggests that the mapping is not a natural equivalence but a constructed analogy, where the concepts of ST must be retrofitted to resemble the terms in Bayes&#39; rule.</span></p><p class="c6"><span class="c1">Third, the mapping of the Bayesian evidence, P(O), is particularly problematic. In Bayesian inference, the evidence is the average likelihood over the entire space of models. The proposed ST equivalent is Cw&#8203;(s), the generation complexity of the single observed situation.</span><span class="c3">13</span><span class="c1 c10">&nbsp;This conflates a property averaged over a distribution of hypotheses with a property of a single instance, overlooking the core mechanism of the Bayesian Occam&#39;s Razor, which operates precisely through this averaging.</span></p><p class="c6 c18"><span class="c1 c10"></span></p><h4 class="c14"><span class="c19 c10">Verdict on the Conjecture</span></h4><p class="c6 c18"><span class="c19 c10"></span></p><p class="c6"><span class="c1 c10">While the formal claim that Bayes&#39; rule is a &quot;specific instance&quot; of ST&#39;s unexpectedness formula appears strained and not rigorously proven, the conjecture should not be dismissed outright. Its true value lies not in establishing formal subsumption, but in serving as a powerful and insightful critique of the axiomatic limitations of standard probability theory from a cognitive perspective. It compellingly argues that a complexity-based framework like ST may be more fundamental or general for describing certain types of human inference&mdash;especially those involving the detection of relevance in unique events, the experience of coincidence, and the generation of subjective surprise&mdash;that fall outside the strict requirements of a measurable event space and probabilistic calculus.</span></p><p class="c6 c18"><span class="c1 c10"></span></p><h3 class="c14"><span class="c19 c10">3.4 Explanatory Power and Limitations</span></h3><p class="c6 c18"><span class="c19 c10"></span></p><p class="c6"><span class="c1 c10">Ultimately, the value of any scientific theory lies in its explanatory power. A comparison of ST and Bayesianism reveals that they are not so much direct competitors as they are specialists with different, though sometimes overlapping, domains of expertise.</span></p><p class="c6 c18"><span class="c1 c10"></span></p><h4 class="c14"><span class="c19 c10">Domains Where ST Excels</span></h4><p class="c6 c18"><span class="c19 c10"></span></p><p class="c14"><span class="c1 c10">Simplicity Theory provides uniquely intuitive and formal explanations for a class of cognitive phenomena that are often difficult to capture with standard Bayesian models. These include:</span></p><ul class="c29 lst-kix_list_2-0 start"><li class="c14 c11 li-bullet-0"><span class="c15">The &quot;Aha!&quot; Moment and Coincidence:</span><span class="c1">&nbsp;ST&#39;s U = C_{gen} - C_{desc} elegantly models the sudden insight that comes from finding a simple pattern in what seemed to be complex data, as well as the uncanny feeling of a meaningful coincidence.</span><span class="c3 c16">1</span></li><li class="c2 c11 li-bullet-0"><span class="c15">Narrative and Relevance:</span><span class="c1">&nbsp;The theory provides a formal basis for what makes a story interesting and worth telling, explaining why we communicate about the unusual and not the mundane.</span><span class="c3 c16">3</span></li><li class="c2 c11 li-bullet-0"><span class="c15">Interest in Deterministic Events:</span><span class="c1">&nbsp;ST can explain why a fully deterministic and predictable event, like a solar eclipse, can still be surprising and interesting to an observer who lacks the correct causal model (i.e., whose Cgen&#8203; is high).</span><span class="c3 c16">13</span></li><li class="c2 c11 li-bullet-0"><span class="c15">Relevance without Big Data:</span><span class="c1">&nbsp;ST proposes a mechanism for a system to identify memorable or anomalous events from a data stream without relying on large datasets for statistical training, a key feature of human cognition.</span><span class="c3 c16">1</span></li></ul><p class="c25 c18"><span class="c3 c16"></span></p><h4 class="c14"><span class="c19 c10">Domains Where Bayesianism Excels</span></h4><p class="c6 c18"><span class="c19 c10"></span></p><p class="c14"><span class="c1 c10">Conversely, the Bayesian framework possesses unparalleled power in domains where ST has limited or no explanatory reach. These are the cornerstones of modern machine learning and rational decision theory:</span></p><ul class="c29 lst-kix_list_3-0 start"><li class="c14 c11 li-bullet-0"><span class="c15">Incremental Learning from Data:</span><span class="c1">&nbsp;The iterative nature of updating a posterior distribution makes Bayesianism the ideal framework for modeling robust, incremental learning over time as new evidence accumulates.</span><span class="c3 c16">19</span></li><li class="c2 c11 li-bullet-0"><span class="c15">Hierarchical Modeling and Knowledge Integration:</span><span class="c1">&nbsp;Bayesian methods allow for the construction of complex hierarchical models that can integrate knowledge and uncertainty at multiple levels of abstraction, a key feature of sophisticated reasoning.</span><span class="c3 c16">14</span></li><li class="c2 c11 li-bullet-0"><span class="c15">Principled Quantification of Uncertainty:</span><span class="c1">&nbsp;The framework provides a complete and coherent system for representing and manipulating uncertainty, not just about data but about model parameters themselves.</span><span class="c3 c16">20</span></li><li class="c2 c11 li-bullet-0"><span class="c15">Optimal Prediction and Decision-Making:</span><span class="c1">&nbsp;Bayesian decision theory combines posterior probabilities with utility functions to provide a normative standard for making optimal choices under ambiguity.</span><span class="c3 c16">32</span></li></ul><p class="c25 c18"><span class="c3 c16"></span></p><h2 class="c14"><span class="c28 c10">Part IV: Integration and Future Directions</span></h2><p class="c6 c18"><span class="c10 c28"></span></p><p class="c6"><span class="c1 c10">The comparative analysis reveals that Simplicity Theory and Bayesian inference, rather than being mutually exclusive opponents, can be viewed as holding a complex and potentially synergistic relationship. Moving beyond a simple versus-style comparison to a more integrated perspective illuminates how these frameworks can coexist, inform each other, and jointly contribute to a more complete science of mind and engineering of intelligence.</span></p><p class="c6 c18"><span class="c1 c10"></span></p><h3 class="c14"><span class="c19 c10">4.1 A Unified View?: Heuristics, Approximations, and Cognitive Reality</span></h3><p class="c6 c18"><span class="c19 c10"></span></p><p class="c6"><span class="c1">The most productive way to reconcile the two frameworks within cognitive science is to frame ST&#39;s mechanism as a descriptive cognitive </span><span class="c7">heuristic</span><span class="c1">&nbsp;that efficiently </span><span class="c7">approximates</span><span class="c1">&nbsp;a Bayesian </span><span class="c7">norm</span><span class="c1 c10">. This reframes their relationship from one of opposition to one of functional, hierarchical integration.</span></p><p class="c6 c18"><span class="c1 c10"></span></p><h4 class="c14"><span class="c19 c10">Simplicity as a Heuristic for Bayesian Inference</span></h4><p class="c6 c18"><span class="c19 c10"></span></p><p class="c6"><span class="c1">Full Bayesian inference, with its need to define priors and integrate over complex parameter spaces, is computationally expensive and often intractable for humans to perform in real-time, especially given limited information and cognitive resources.</span><span class="c3">22</span><span class="c1">&nbsp;Cognitive science has long recognized that humans rely on a wide range of &quot;fast and frugal&quot; heuristics to make decisions under uncertainty.</span><span class="c3">42</span><span class="c1">&nbsp;The principle of parsimony, or Occam&#39;s Razor, is one of the most powerful and pervasive of these heuristics, with ample research demonstrating a strong and robust human preference for simpler explanations.</span><span class="c3 c16">6</span></p><p class="c6"><span class="c1">The Bayesian Occam&#39;s Razor provides the </span><span class="c7">normative justification</span><span class="c1">&nbsp;for this cognitive preference. It demonstrates, through the mathematics of model evidence, that this bias towards simplicity is not arbitrary or merely aesthetic; simpler hypotheses are, in a formal sense, often more probable.</span><span class="c3 c16">25</span></p><p class="c6 c18"><span class="c3 c16"></span></p><h4 class="c14"><span class="c19 c10">Evidence from Cognitive Science</span></h4><p class="c6 c18"><span class="c19 c10"></span></p><p class="c6"><span class="c1">This theoretical link is supported by empirical evidence. Studies have shown that when faced with uncertain explanations, people use an explanation&#39;s simplicity as a direct cue to infer its prior probability and its likelihood of being true.</span><span class="c3">41</span><span class="c1">&nbsp;This effect is particularly strong when the formal Bayesian calculation is difficult or when the necessary probabilistic information is missing, suggesting that simplicity serves as a cognitive shortcut to approximate the output of a more complex rational calculation.</span><span class="c3 c16">41</span></p><p class="c6 c18"><span class="c3 c16"></span></p><h4 class="c14"><span class="c19 c10">Reconciling the Frameworks</span></h4><p class="c6 c18"><span class="c19 c10"></span></p><p class="c6"><span class="c1">This perspective offers a powerful reconciliation. Simplicity Theory can be understood not as an &quot;opponent&quot; to Bayesianism in the cognitive realm, but as a descriptive, algorithmic-level model of the </span><span class="c7">process</span><span class="c1">&nbsp;the brain might use to implement a &quot;good enough,&quot; resource-bounded version of Bayesian (or more broadly, rational) inference. ST provides a precise, mechanistic account of </span><span class="c7">how</span><span class="c1">&nbsp;the brain might implement the simplicity heuristic: by being hard-wired to detect a &quot;complexity drop&quot; via the U = C_{gen} - C_{desc} computation. This mechanism is fast, efficient, and does not require the explicit calculation of probabilities or the integration over belief distributions. In the language of dual-process theory, ST could be seen as describing the fast, intuitive System 1, which generates proposals and flags events based on their salience, while formal Bayesianism describes the slow, deliberative System 2 or the normative ideal that the entire cognitive system strives toward.</span><span class="c3 c16">34</span></p><p class="c6 c18"><span class="c3 c16"></span></p><h3 class="c14"><span class="c19 c10">4.2 Implications for Artificial Intelligence</span></h3><p class="c6 c18"><span class="c19 c10"></span></p><p class="c6"><span class="c1 c10">The choice between these two frameworks has profound implications for the goals and methods of artificial intelligence research. The question &quot;Which theory is better for AI?&quot; depends entirely on what kind of intelligence one aims to build.</span></p><p class="c6 c18"><span class="c1 c10"></span></p><h4 class="c14"><span class="c19 c10">AI based on ST</span></h4><p class="c6 c18"><span class="c19 c10"></span></p><p class="c14"><span class="c1">Adopting Simplicity Theory as a guiding principle would lead to the development of AI systems with a more human-like sense of relevance and interest. The goal would be to create machines that can identify &quot;memorable,&quot; &quot;interesting,&quot; or &quot;anomalous&quot; events from a massive, unstructured stream of data without extensive prior training or labeled examples.</span><span class="c3">1</span><span class="c1 c10">&nbsp;This has direct applications in:</span></p><ul class="c29 lst-kix_list_4-0 start"><li class="c14 c11 li-bullet-0"><span class="c15">Data Summarization:</span><span class="c1 c10">&nbsp;Automatically generating concise summaries of large datasets or long periods of activity by highlighting only the most unexpected events.</span></li><li class="c2 c11 li-bullet-0"><span class="c15">Anomaly Detection:</span><span class="c1 c10">&nbsp;Identifying potential system failures or security threats by flagging situations that are abnormally simple compared to their expected causal complexity.</span></li><li class="c2 c11 li-bullet-0"><span class="c15">Human-Computer Interaction:</span><span class="c1">&nbsp;Creating more natural and engaging conversational agents that can understand what a human user would find interesting to discuss, avoiding the reporting of mundane facts and focusing on narratively relevant information.</span><span class="c3">1</span><span class="c24 c10"><br><br></span><span class="c1 c10">The CompLog system, a proof-of-concept that uses ST&#39;s inferential mechanisms for reasoning, provides a concrete example of this research direction.1</span></li></ul><p class="c18 c25"><span class="c1 c10"></span></p><h4 class="c14"><span class="c19 c10">AI based on Bayesianism</span></h4><p class="c6 c18"><span class="c19 c10"></span></p><p class="c14"><span class="c1 c10">The Bayesian approach is already a well-established and dominant paradigm in a vast portion of modern machine learning and AI. It is the foundation for systems that excel at:</span></p><ul class="c29 lst-kix_list_5-0 start"><li class="c14 c11 li-bullet-0"><span class="c15">Robust Prediction and Classification:</span><span class="c1 c10">&nbsp;Building models that can make accurate predictions under uncertainty, from medical diagnosis to financial forecasting.</span></li><li class="c2 c11 li-bullet-0"><span class="c15">Learning from Data:</span><span class="c1 c10">&nbsp;Developing algorithms that can learn the parameters of complex models from data in a principled and robust manner.</span></li><li class="c2 c11 li-bullet-0"><span class="c15">Probabilistic Reasoning:</span><span class="c1">&nbsp;Constructing expert systems, such as Bayesian networks, that can reason about cause and effect in complex domains where knowledge is incomplete.</span><span class="c3 c16">14</span></li></ul><p class="c25 c18"><span class="c3 c16"></span></p><h4 class="c14"><span class="c19 c10">A Hybrid Future</span></h4><p class="c6 c18"><span class="c19 c10"></span></p><p class="c6"><span class="c1 c10">The most promising future direction for building general and flexible AI likely lies in hybrid systems that combine the strengths of both approaches. One can envision an architecture where powerful Bayesian methods form the backbone of the system, responsible for robust learning, probabilistic reasoning, and optimal decision-making. Layered on top of or integrated with this backbone would be ST-like mechanisms designed to guide the focus of attention. These complexity-based modules could act as a relevance filter, identifying the most salient data points from a high-bandwidth input stream to be fed into the more computationally expensive Bayesian machinery. Such a hybrid system could learn robustly like a machine while attending to the world with the relevance-detecting acuity of a human.</span></p><p class="c6 c18"><span class="c1 c10"></span></p><h3 class="c14"><span class="c19 c10">4.3 Conclusion: Complementary Frameworks for a Science of Mind</span></h3><p class="c6 c18"><span class="c19 c10"></span></p><p class="c6"><span class="c1 c10">This comprehensive analysis of Simplicity Theory and Bayesian model inference leads to a nuanced conclusion that rejects a simple adversarial view in favor of a complementary partnership.</span></p><p class="c6 c18"><span class="c1 c10"></span></p><h4 class="c14"><span class="c19 c10">Summary of Findings</span></h4><p class="c6 c18"><span class="c19 c10"></span></p><p class="c6"><span class="c1 c10">The two frameworks originate from fundamentally different theoretical traditions&mdash;Algorithmic Information Theory and Probability Theory, respectively. This foundational difference leads them to have distinct primary explanatory targets: ST focuses on explaining the cognitive salience of unique, individual events, while Bayesianism provides a general framework for updating beliefs about the generative models that produce data streams. Consequently, their approaches to the principle of parsimony, or Occam&#39;s Razor, are distinct. ST employs a direct, subtractive calculation of a &quot;complexity drop&quot; (U=Cgen&#8203;&minus;Cdesc&#8203;), a post-hoc analysis of a single event&#39;s properties. In contrast, the Bayesian Occam&#39;s Razor is an emergent property of model evidence, arising from an average-case evaluation of a model&#39;s predictive performance across its entire parameter space.</span></p><p class="c6 c18"><span class="c1 c10"></span></p><h4 class="c14"><span class="c10 c19">Rejecting a Zero-Sum View</span></h4><p class="c6 c18"><span class="c19 c10"></span></p><p class="c6"><span class="c1 c10">The analysis demonstrates that a zero-sum view, in which one theory must be &quot;right&quot; and the other &quot;wrong,&quot; is unproductive and misleading. The question &quot;Which theory is better?&quot; is ill-posed without first specifying the context and the precise explanatory goal. ST provides a superior explanation for the subjective experience of coincidence, while Bayesianism provides a superior framework for optimal learning from statistical data.</span></p><p class="c6 c18"><span class="c1 c10"></span></p><h4 class="c14"><span class="c19 c10">A Complementary Partnership</span></h4><p class="c6 c18"><span class="c19 c10"></span></p><p class="c27"><span class="c1 c10">The final verdict is that Simplicity Theory and Bayesian inference offer a powerful and complementary partnership for a comprehensive science of mind. Simplicity Theory provides a unique, formal, and predictive descriptive theory for a specific and crucial set of cognitive faculties: the detection of relevance, the generation of interest, and the structuring of narrative. These are the mechanisms that guide our attention and communication. Bayesian inference, in turn, provides a broad and powerful normative and descriptive framework for the general problem of learning, reasoning, and decision-making under the pervasive uncertainty that characterizes our world. A complete understanding of cognition requires both the specific, algorithmic lens of Simplicity Theory to explain what we find interesting, and the general, probabilistic framework of Bayesianism to explain how we learn from what we find. Together, they offer a richer and more complete picture of the computational architecture of the human mind.</span></p><h4 class="c32"><span class="c10 c33">Works cited</span></h4><ol class="c29 lst-kix_list_6-0 start" start="1"><li class="c0 li-bullet-0"><span class="c23">Jean-Louis Dessalles - Home page, accessed July 17, 2025, </span><span class="c13"><a class="c4" href="https://www.google.com/url?q=https://perso.telecom-paristech.fr/jld/papiers/simplicity.html&amp;sa=D&amp;source=editors&amp;ust=1752770122367590&amp;usg=AOvVaw1VEKHX9CcOzB8jFFPsGK3v">https://perso.telecom-paristech.fr/jld/papiers/simplicity.html</a></span></li><li class="c0 li-bullet-0"><span class="c23">Simplicity theory - Wikipedia, accessed July 17, 2025, </span><span class="c13"><a class="c4" href="https://www.google.com/url?q=https://en.wikipedia.org/wiki/Simplicity_theory&amp;sa=D&amp;source=editors&amp;ust=1752770122368130&amp;usg=AOvVaw2RDNt-R9sjItkv53c3c9kK">https://en.wikipedia.org/wiki/Simplicity_theory</a></span></li><li class="c0 li-bullet-0"><span class="c23">(PDF) Algorithmic Simplicity and Relevance - ResearchGate, accessed July 17, 2025, </span><span class="c13"><a class="c4" href="https://www.google.com/url?q=https://www.researchgate.net/publication/230639494_Algorithmic_Simplicity_and_Relevance&amp;sa=D&amp;source=editors&amp;ust=1752770122368850&amp;usg=AOvVaw2NTpV7lzmugdvkCi5-DVWM">https://www.researchgate.net/publication/230639494_Algorithmic_Simplicity_and_Relevance</a></span></li><li class="c0 li-bullet-0"><span class="c23">Kolmogorov complexity - Wikipedia, accessed July 17, 2025, </span><span class="c13"><a class="c4" href="https://www.google.com/url?q=https://en.wikipedia.org/wiki/Kolmogorov_complexity&amp;sa=D&amp;source=editors&amp;ust=1752770122369304&amp;usg=AOvVaw2R2wLdeK2Y_0VAlTwhSgLW">https://en.wikipedia.org/wiki/Kolmogorov_complexity</a></span></li><li class="c0 li-bullet-0"><span class="c23">Kolmogorov Complexity &amp; Minimum Description Length - Statistics How To, accessed July 17, 2025, </span><span class="c13"><a class="c4" href="https://www.google.com/url?q=https://www.statisticshowto.com/minimum-description-length-kolmogorov-complexity/&amp;sa=D&amp;source=editors&amp;ust=1752770122370239&amp;usg=AOvVaw0JiiuK-qrG9mNOPM0qiV7i">https://www.statisticshowto.com/minimum-description-length-kolmogorov-complexity/</a></span></li><li class="c0 li-bullet-0"><span class="c23">The simplicity principle in perception and cognition - PMC - PubMed Central, accessed July 17, 2025, </span><span class="c13"><a class="c4" href="https://www.google.com/url?q=https://pmc.ncbi.nlm.nih.gov/articles/PMC5125387/&amp;sa=D&amp;source=editors&amp;ust=1752770122370853&amp;usg=AOvVaw3clv3SMmF505bOHJ4UcAI2">https://pmc.ncbi.nlm.nih.gov/articles/PMC5125387/</a></span></li><li class="c0 li-bullet-0"><span class="c23">The Simplicity Principle in Human Concept Learning - Rutgers Center for Cognitive Science, accessed July 17, 2025, </span><span class="c13"><a class="c4" href="https://www.google.com/url?q=https://ruccs.rutgers.edu/images/personal-jacob-feldman/papers/feldman_CDPS.pdf&amp;sa=D&amp;source=editors&amp;ust=1752770122371489&amp;usg=AOvVaw1Sv0yVGEuDJ51YHm503eE8">https://ruccs.rutgers.edu/images/personal-jacob-feldman/papers/feldman_CDPS.pdf</a></span></li><li class="c0 li-bullet-0"><span class="c23">The simplicity principle in perception and cognition, accessed July 17, 2025, </span><span class="c13"><a class="c4" href="https://www.google.com/url?q=http://ruccs.rutgers.edu/images/personal-jacob-feldman/papers/feldman_simplicity_2016.pdf&amp;sa=D&amp;source=editors&amp;ust=1752770122372268&amp;usg=AOvVaw0A08VORY-73uR2_j0LXBGt">http://ruccs.rutgers.edu/images/personal-jacob-feldman/papers/feldman_simplicity_2016.pdf</a></span></li><li class="c0 li-bullet-0"><span class="c23">Minimum description length - Wikipedia, accessed July 17, 2025, </span><span class="c13"><a class="c4" href="https://www.google.com/url?q=https://en.wikipedia.org/wiki/Minimum_description_length&amp;sa=D&amp;source=editors&amp;ust=1752770122372898&amp;usg=AOvVaw0sASZ-olSW-157rOGzts8w">https://en.wikipedia.org/wiki/Minimum_description_length</a></span></li><li class="c0 li-bullet-0"><span class="c23">Simplicity Theory, accessed July 17, 2025, </span><span class="c13"><a class="c4" href="https://www.google.com/url?q=https://simplicitytheory.telecom-paris.fr/&amp;sa=D&amp;source=editors&amp;ust=1752770122373335&amp;usg=AOvVaw2dHr38iLxXeUPqGMCGFScs">https://simplicitytheory.telecom-paris.fr/</a></span></li><li class="c0 li-bullet-0"><span class="c23">Simplicity theory: teaching relevances to artificial intelligences - I&#39;MTech, accessed July 17, 2025, </span><span class="c13"><a class="c4" href="https://www.google.com/url?q=https://imtech.imt.fr/en/2016/10/28/simplicity-theory-teaching-relevance-ai/&amp;sa=D&amp;source=editors&amp;ust=1752770122373989&amp;usg=AOvVaw29C3JFxx6c5LiM0UobaHcF">https://imtech.imt.fr/en/2016/10/28/simplicity-theory-teaching-relevance-ai/</a></span></li><li class="c0 li-bullet-0"><span class="c23">Conversational topic connectedness predicted by Simplicity Theory - eScholarship.org, accessed July 17, 2025, </span><span class="c13"><a class="c4" href="https://www.google.com/url?q=https://escholarship.org/uc/item/8kt3d66b&amp;sa=D&amp;source=editors&amp;ust=1752770122374520&amp;usg=AOvVaw314QJIJLTmzsoAHNpAYP5r">https://escholarship.org/uc/item/8kt3d66b</a></span></li><li class="c0 li-bullet-0"><span class="c23">UvA-DARE (Digital Academic Repository), accessed July 17, 2025, </span><span class="c13"><a class="c4" href="https://www.google.com/url?q=https://pure.uva.nl/ws/files/134178934/978_3_031_12429_7_8.pdf&amp;sa=D&amp;source=editors&amp;ust=1752770122374958&amp;usg=AOvVaw08gpjphsemk9WQvbMDmQ3l">https://pure.uva.nl/ws/files/134178934/978_3_031_12429_7_8.pdf</a></span></li><li class="c0 li-bullet-0"><span class="c23">Unexpectedness and Bayes&#39; Rule | Request PDF - ResearchGate, accessed July 17, 2025, </span><span class="c13"><a class="c4" href="https://www.google.com/url?q=https://www.researchgate.net/publication/367584737_Unexpectedness_and_Bayes&#39;_Rule&amp;sa=D&amp;source=editors&amp;ust=1752770122375475&amp;usg=AOvVaw3AF1BxpQnZGNIhPdJ1Bfgb">https://www.researchgate.net/publication/367584737_Unexpectedness_and_Bayes&#39;_Rule</a></span></li><li class="c0 li-bullet-0"><span class="c23">Normative vs. descriptive models - (Intermediate Microeconomic Theory) - Vocab, Definition, Explanations | Fiveable, accessed July 17, 2025, </span><span class="c13"><a class="c4" href="https://www.google.com/url?q=https://library.fiveable.me/key-terms/intermediate-microeconomic-theory/normative-vs-descriptive-models&amp;sa=D&amp;source=editors&amp;ust=1752770122376094&amp;usg=AOvVaw0WvMHGSrGRM81_CkaTa91e">https://library.fiveable.me/key-terms/intermediate-microeconomic-theory/normative-vs-descriptive-models</a></span></li><li class="c0 li-bullet-0"><span class="c23">Descriptive Decision Theory (Stanford Encyclopedia of Philosophy), accessed July 17, 2025, </span><span class="c13"><a class="c4" href="https://www.google.com/url?q=https://plato.stanford.edu/entries/decision-theory-descriptive/&amp;sa=D&amp;source=editors&amp;ust=1752770122376515&amp;usg=AOvVaw3sNbljRdeQgd5JBUmTZ1LW">https://plato.stanford.edu/entries/decision-theory-descriptive/</a></span></li><li class="c0 li-bullet-0"><span class="c23">(PDF) Unexpectedness and Bayes&#39; Rule - ResearchGate, accessed July 17, 2025, </span><span class="c13"><a class="c4" href="https://www.google.com/url?q=https://www.researchgate.net/publication/364382008_Unexpectedness_and_Bayes&#39;_Rule&amp;sa=D&amp;source=editors&amp;ust=1752770122376985&amp;usg=AOvVaw1QCB8bJJT-VYbf3dkzL9CG">https://www.researchgate.net/publication/364382008_Unexpectedness_and_Bayes&#39;_Rule</a></span></li><li class="c0 li-bullet-0"><span class="c23">Bayesian inference | Introduction with explained examples - StatLect, accessed July 17, 2025, </span><span class="c13"><a class="c4" href="https://www.google.com/url?q=https://www.statlect.com/fundamentals-of-statistics/Bayesian-inference&amp;sa=D&amp;source=editors&amp;ust=1752770122377418&amp;usg=AOvVaw2EPEe2k4z--JTFJ99i1Ta-">https://www.statlect.com/fundamentals-of-statistics/Bayesian-inference</a></span></li><li class="c0 li-bullet-0"><span class="c23">Bayesian inference - Wikipedia, accessed July 17, 2025, </span><span class="c13"><a class="c4" href="https://www.google.com/url?q=https://en.wikipedia.org/wiki/Bayesian_inference&amp;sa=D&amp;source=editors&amp;ust=1752770122377830&amp;usg=AOvVaw1-5PuP2P2GHf0_bYED2IhN">https://en.wikipedia.org/wiki/Bayesian_inference</a></span></li><li class="c0 li-bullet-0"><span class="c23">Bayesian Statistics: A Beginner&#39;s Guide | QuantStart, accessed July 17, 2025, </span><span class="c13"><a class="c4" href="https://www.google.com/url?q=https://www.quantstart.com/articles/Bayesian-Statistics-A-Beginners-Guide/&amp;sa=D&amp;source=editors&amp;ust=1752770122378252&amp;usg=AOvVaw06ORetxyr4U2OhoxOywy5P">https://www.quantstart.com/articles/Bayesian-Statistics-A-Beginners-Guide/</a></span></li><li class="c0 li-bullet-0"><span class="c23">The Basics of the Bayesian Approach: An Introductory Tutorial - The Change Lab, accessed July 17, 2025, </span><span class="c13"><a class="c4" href="https://www.google.com/url?q=https://thechangelab.stanford.edu/tutorials/bayesian-methods/the-basics-of-the-bayesian-approach-an-introductory-tutorial/&amp;sa=D&amp;source=editors&amp;ust=1752770122378861&amp;usg=AOvVaw0ld26SJmfAwxqrJUM6RK5N">https://thechangelab.stanford.edu/tutorials/bayesian-methods/the-basics-of-the-bayesian-approach-an-introductory-tutorial/</a></span></li><li class="c0 li-bullet-0"><span class="c23">10 Steps to Master Bayesian Inference: A Practical Guide - Number Analytics, accessed July 17, 2025, </span><span class="c13"><a class="c4" href="https://www.google.com/url?q=https://www.numberanalytics.com/blog/10-steps-to-master-bayesian-inference-practical-guide&amp;sa=D&amp;source=editors&amp;ust=1752770122379469&amp;usg=AOvVaw3Ypu6jOiwu9PhpWsXDWse3">https://www.numberanalytics.com/blog/10-steps-to-master-bayesian-inference-practical-guide</a></span></li><li class="c0 li-bullet-0"><span class="c23">Bayesian Inference - Introduction to Machine Learning - Wolfram, accessed July 17, 2025, </span><span class="c13"><a class="c4" href="https://www.google.com/url?q=https://www.wolfram.com/language/introduction-machine-learning/bayesian-inference/&amp;sa=D&amp;source=editors&amp;ust=1752770122379988&amp;usg=AOvVaw0LDAvZqCBlfFbnl4x2FSBO">https://www.wolfram.com/language/introduction-machine-learning/bayesian-inference/</a></span></li><li class="c0 li-bullet-0"><span class="c23">Chapter 12 Bayesian Inference - Statistics &amp; Data Science, accessed July 17, 2025, </span><span class="c13"><a class="c4" href="https://www.google.com/url?q=https://www.stat.cmu.edu/~larry/%3Dsml/Bayes.pdf&amp;sa=D&amp;source=editors&amp;ust=1752770122380410&amp;usg=AOvVaw3aYlwk6gRBnkkW8VvNrFZz">https://www.stat.cmu.edu/~larry/=sml/Bayes.pdf</a></span></li><li class="c0 li-bullet-0"><span class="c23">Model Comparison and Occam&#39;s Razor, accessed July 17, 2025, </span><span class="c13"><a class="c4" href="https://www.google.com/url?q=https://www.inference.org.uk/mackay/itprnn/ps/343.355.pdf&amp;sa=D&amp;source=editors&amp;ust=1752770122380773&amp;usg=AOvVaw0w6artmHCbFkhtNVab9j8l">https://www.inference.org.uk/mackay/itprnn/ps/343.355.pdf</a></span></li><li class="c0 li-bullet-0"><span class="c23">Bayesian Occam&#39;s Razor Is a Razor of the People, accessed July 17, 2025, </span><span class="c13"><a class="c4" href="https://www.google.com/url?q=https://cognition.princeton.edu/document/125&amp;sa=D&amp;source=editors&amp;ust=1752770122381128&amp;usg=AOvVaw1z7e4K7bLYRGV7lNP0yG8t">https://cognition.princeton.edu/document/125</a></span></li><li class="c0 li-bullet-0"><span class="c23">SHARPENING OCKHAM&#39;S RAZOR ON A BAYESIAN STROP by William H. Je erys University of Texas at Austin and James O. Berger Purdue Uni, accessed July 17, 2025, </span><span class="c13"><a class="c4" href="https://www.google.com/url?q=https://quasar.as.utexas.edu/papers/ockham.pdf&amp;sa=D&amp;source=editors&amp;ust=1752770122381637&amp;usg=AOvVaw3SLlnZka4fTNI1DZU_F04E">https://quasar.as.utexas.edu/papers/ockham.pdf</a></span></li><li class="c0 li-bullet-0"><span class="c23">Occam&#39;s Razor - Probabilistic Models of Cognition, accessed July 17, 2025, </span><span class="c13"><a class="c4" href="https://www.google.com/url?q=http://probmods.org/chapters/occams-razor.html&amp;sa=D&amp;source=editors&amp;ust=1752770122382027&amp;usg=AOvVaw1X6fxHg-UqlVJOHs0Pi0bF">http://probmods.org/chapters/occams-razor.html</a></span></li><li class="c0 li-bullet-0"><span class="c23">Simplicity in the Philosophy of Science, accessed July 17, 2025, </span><span class="c13"><a class="c4" href="https://www.google.com/url?q=https://iep.utm.edu/simplici/&amp;sa=D&amp;source=editors&amp;ust=1752770122382368&amp;usg=AOvVaw30_v-Gq50_A6VkYQdhpOZZ">https://iep.utm.edu/simplici/</a></span></li><li class="c0 li-bullet-0"><span class="c23">A note on the evidence and Bayesian Occam&#39;s razor, accessed July 17, 2025, </span><span class="c13"><a class="c4" href="https://www.google.com/url?q=https://mlg.eng.cam.ac.uk/zoubin/papers/05occam/occam.pdf&amp;sa=D&amp;source=editors&amp;ust=1752770122382781&amp;usg=AOvVaw2k4pAG9hjvxf2n27ia-fZQ">https://mlg.eng.cam.ac.uk/zoubin/papers/05occam/occam.pdf</a></span></li><li class="c0 li-bullet-0"><span class="c23">Bayesian Cognitive Science, Monopoly, and Neglected Frameworks - Open Access LMU, accessed July 17, 2025, </span><span class="c13"><a class="c4" href="https://www.google.com/url?q=https://epub.ub.uni-muenchen.de/41932/2/BayesCogSci_final.pdf&amp;sa=D&amp;source=editors&amp;ust=1752770122383257&amp;usg=AOvVaw0Phkxumo9Dk6rMGx9RCVo6">https://epub.ub.uni-muenchen.de/41932/2/BayesCogSci_final.pdf</a></span></li><li class="c0 li-bullet-0"><span class="c23">A Realist Perspective on Bayesian Cognitive Science Michael Rescorla Abstract - Philosophy - UCLA, accessed July 17, 2025, </span><span class="c13"><a class="c4" href="https://www.google.com/url?q=https://philosophy.ucla.edu/wp-content/uploads/2016/08/Realist-Perspective-.pdf&amp;sa=D&amp;source=editors&amp;ust=1752770122383776&amp;usg=AOvVaw2qXGM6u-rC2QjXtSyq2yJA">https://philosophy.ucla.edu/wp-content/uploads/2016/08/Realist-Perspective-.pdf</a></span></li><li class="c0 li-bullet-0"><span class="c23">Bayesian models of cognitive development Elizabeth Bonawitz &amp; Tomer Ullman - Projects at Harvard, accessed July 17, 2025, </span><span class="c13"><a class="c4" href="https://www.google.com/url?q=https://projects.iq.harvard.edu/sites/projects.iq.harvard.edu/files/bbb_chapter20.pdf&amp;sa=D&amp;source=editors&amp;ust=1752770122384334&amp;usg=AOvVaw3I3feolUauFcjFKjp1oMTl">https://projects.iq.harvard.edu/sites/projects.iq.harvard.edu/files/bbb_chapter20.pdf</a></span></li><li class="c0 li-bullet-0"><span class="c23">Discrepancies between normative and descriptive models of decision making and the understanding/acceptance principle - PubMed, accessed July 17, 2025, </span><span class="c13"><a class="c4" href="https://www.google.com/url?q=https://pubmed.ncbi.nlm.nih.gov/10328857/&amp;sa=D&amp;source=editors&amp;ust=1752770122384787&amp;usg=AOvVaw3CYMht9kvqrHMCtEpVG4mV">https://pubmed.ncbi.nlm.nih.gov/10328857/</a></span></li><li class="c0 li-bullet-0"><span class="c23">Behavioral Decision Making in Normative and Descriptive Views: A Critical Review of Literature - MDPI, accessed July 17, 2025, </span><span class="c13"><a class="c4" href="https://www.google.com/url?q=https://www.mdpi.com/1911-8074/14/10/490&amp;sa=D&amp;source=editors&amp;ust=1752770122385236&amp;usg=AOvVaw2T4h6EKxPy2tkATyet0V-g">https://www.mdpi.com/1911-8074/14/10/490</a></span></li><li class="c0 li-bullet-0"><span class="c23">A Tutorial Introduction to the Minimum Description Length Principle - CWI, accessed July 17, 2025, </span><span class="c13"><a class="c4" href="https://www.google.com/url?q=https://homepages.cwi.nl/~pdg/ftp/mdlintro.pdf&amp;sa=D&amp;source=editors&amp;ust=1752770122385675&amp;usg=AOvVaw3IEbMAusrY0C3G9Uh3czrU">https://homepages.cwi.nl/~pdg/ftp/mdlintro.pdf</a></span></li><li class="c0 li-bullet-0"><span class="c23">Minimum Message Length and Kolmogorov Complexity - CiteSeerX, accessed July 17, 2025, </span><span class="c13"><a class="c4" href="https://www.google.com/url?q=https://citeseerx.ist.psu.edu/document?repid%3Drep1%26type%3Dpdf%26doi%3D4ef08582dc5c11b3286b463307dd6ee739d2f8c6&amp;sa=D&amp;source=editors&amp;ust=1752770122386215&amp;usg=AOvVaw0iGJRlWa6AQgb4pocamIRK">https://citeseerx.ist.psu.edu/document?repid=rep1&amp;type=pdf&amp;doi=4ef08582dc5c11b3286b463307dd6ee739d2f8c6</a></span></li><li class="c0 li-bullet-0"><span class="c23">MDL, Bayesian Inference and the Geometry of the Space of ..., accessed July 17, 2025, </span><span class="c13"><a class="c4" href="https://www.google.com/url?q=https://www.sas.upenn.edu/~vbalasub/public-html/Inference_files/MDLChapter.pdf&amp;sa=D&amp;source=editors&amp;ust=1752770122386770&amp;usg=AOvVaw2CKdBr6Ja59JB3LbrKkaIU">https://www.sas.upenn.edu/~vbalasub/public-html/Inference_files/MDLChapter.pdf</a></span></li><li class="c0 li-bullet-0"><span class="c23">(PDF) Minimum Description Length Induction, Bayesianism, and Kolmogorov Complexity, accessed July 17, 2025, </span><span class="c13"><a class="c4" href="https://www.google.com/url?q=https://www.researchgate.net/publication/301882515_Minimum_Description_Length_Induction_Bayesianism_and_Kolmogorov_Complexity&amp;sa=D&amp;source=editors&amp;ust=1752770122387663&amp;usg=AOvVaw295tIkOsvioleNrms6u-NK">https://www.researchgate.net/publication/301882515_Minimum_Description_Length_Induction_Bayesianism_and_Kolmogorov_Complexity</a></span></li><li class="c0 li-bullet-0"><span class="c23">Minimum Description Length Induction, Bayesianism, and ... - arXiv, accessed July 17, 2025, </span><span class="c13"><a class="c4" href="https://www.google.com/url?q=https://arxiv.org/pdf/cs/9901014&amp;sa=D&amp;source=editors&amp;ust=1752770122388080&amp;usg=AOvVaw0Ph-N1cfw2ufPZ4ICx1LiE">https://arxiv.org/pdf/cs/9901014</a></span></li><li class="c0 li-bullet-0"><span class="c23">Simplicity as a Cue to Probability: Multiple Roles for Simplicity in ..., accessed July 17, 2025, </span><span class="c13"><a class="c4" href="https://www.google.com/url?q=https://cognition.princeton.edu/sites/g/files/toruqf3386/files/cognitive_science_-_2022_-_vrantsidis_-_simplicity_as_a_cue_to_probability_multiple_roles_for_simplicity_in_evaluating.pdf&amp;sa=D&amp;source=editors&amp;ust=1752770122389018&amp;usg=AOvVaw2cACEchaISYs_VGd5jLqnL">https://cognition.princeton.edu/sites/g/files/toruqf3386/files/cognitive_science_-_2022_-_vrantsidis_-_simplicity_as_a_cue_to_probability_multiple_roles_for_simplicity_in_evaluating.pdf</a></span></li><li class="c0 li-bullet-0"><span class="c23">Decision-Making Models | Cognitive Psychology Class Notes - Fiveable, accessed July 17, 2025, </span><span class="c13"><a class="c4" href="https://www.google.com/url?q=https://library.fiveable.me/cognitive-psychology/unit-11/decision-making-models/study-guide/ZfFUqJu7OgvQsuNu&amp;sa=D&amp;source=editors&amp;ust=1752770122389625&amp;usg=AOvVaw1dMEhl0cdWrwai0o2uqlQ7">https://library.fiveable.me/cognitive-psychology/unit-11/decision-making-models/study-guide/ZfFUqJu7OgvQsuNu</a></span></li><li class="c0 li-bullet-0"><span class="c23">Bayes and the Simplicity Principle in Perception - Rutgers Center for Cognitive Science, accessed July 17, 2025, </span><span class="c13"><a class="c4" href="https://www.google.com/url?q=https://ruccs.rutgers.edu/images/personal-jacob-feldman/papers/feldman_psychreview2009.pdf&amp;sa=D&amp;source=editors&amp;ust=1752770122390152&amp;usg=AOvVaw0-M513imqgJokbMzDY6WVY">https://ruccs.rutgers.edu/images/personal-jacob-feldman/papers/feldman_psychreview2009.pdf</a></span></li></ol></body></html>